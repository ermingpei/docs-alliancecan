<languages />
=Utilisez plutôt [[Apptainer/fr|Apptainer]]=
<b>Le contenu de cette page est désuet puisque Singularity n'est plus supporté. Consultez notre page wiki sur [[Apptainer/fr|Apptainer]].</b>

=Généralités=
Singularity<ref>Site web Singularity, https://www.sylabs.io/docs/</ref> est un logiciel libre (''open source'') créé par Berkeley Lab pour
* utiliser '''de façon sécuritaire''' des conteneurs Linux sur des grappes Linux multiutilisateur;
* donner aux utilisateurs le '''plein contrôle de leur environnement''';
* '''créer des paquets de logiciels scientifiques''' et les déployer sur des grappes différentes de même architecture.
Singularity permet la virtualisation du système d’exploitation sous la forme de '''conteneurs'''.

À la différence d’une instance (machine virtuelle), un conteneur
* exige possiblement moins de ressources;
* peut seulement exécuter des programmes conçus pour le même noyau (ici Linux) avec une même architecture matérielle.

Une instance peut exécuter plus d’un système d’exploitation et peut quelquefois servir à exécuter des programmes conçus pour des architectures CPU différentes.

Les conteneurs font usage des fonctionnalités Linux 
* '''cgroups''' pour limiter, contrôler et isoler l’utilisation des ressources (par exemple la mémoire vive, les disques I/O, l’accès au CPU);
* '''kernel namespaces''' pour virtualiser et isoler les ressources du système d’exploitation d’un groupe de processus (par exemple les processus et les identifiants d’utilisateurs, les systèmes de fichiers, l’accès au réseau);
* '''systèmes de fichiers Overlay''' pour donner l’apparence d’opérations d’écriture dans des systèmes de fichiers à lecture seule.

Contrairement à d’autres solutions de conteneurs comme Docker<ref>Site web Docker, https://www.docker.com/</ref>, Singularity permet d’utiliser les conteneurs de façon sécuritaire, particulièrement avec les grappes de calcul multiutilisateur.<ref> Documentation de sécurité Singularity,  https://www.sylabs.io/guides/2.5.1/admin-guide/security.html</ref>

=Disponibilité=

Singularity est disponible sur nos grappes.

Si vous voulez utiliser Singularity sur votre propre ordinateur, consultez la documentation d’installation <ref>Documentation d'installation Singularity, https://www.sylabs.io/docs/</ref>. Vous devriez disposer d’une distribution Linux relativement récente (noyau de v3 10.0 ou plus).

=Utiliser Singularity sur nos grappes=

==Charger un module==

Chargez d’abord le module que vous voulez utiliser, par exemple
<source lang="console">$ module load singularity/2.5</source>

Voyez les modules disponibles avec
<source lang="console">$ module spider singularity</source>

==Créer des images==

Avant d’utiliser Singularity, vous devez créer une image (un conteneur). Cette image est soit un fichier, soit un répertoire dans lequel Linux est installé. Pour créer une image, utilisez la commande <code>singularity build</code>, soit
* <code>singularity build WHAT-TO-WRITE SPECIAL-URI-OR-PATH</code>
où <code>WHAT-TO-WRITE</code> peut être
* le nom du fichier de l'image Singularity (*.sif) où l'image construite sera écrite 
* un répertoire si vous construisez un bac à sable avec l'option '''--sandbox''', généralement sur votre propre ordinateur Linux (avec un compte d'accès ''root'') 
et <code>SPECIAL-URI-OR-PATH</code> peut être
* une adresse URI commençant par '''library://''' pour construire à partir d'une bibliothèque de conteneurs,
* une adresse URI commençant par '''docker://''' pour construire à partir de Docker Hub,
* une adresse URI commençant par '''shub://''' pour construire à partir de Singularity Hub,
* un chemin vers un conteneur existant,
* un chemin vers un répertoire pour construire à partir d'un bac à sable,
* un chemin vers un fichier de l'image Singularity (qui est une recette pour construire l'image).

===Avertissement===

Il est fortement recommandé de créer les images Singularity sur un ordinateur ou dans une instance
* dont le système d'exploitation est Linux,
* où Singularity est installé,
* avec un accès à l'internet,
* de préférence où vous êtes utilisateur racine (''root''), soit avec les permissions <code>sudo</code>.

Sans permissions <code>sudo</code>, sachez que '''toutes les permissions (de l'utilisateur et du groupe) pour l'image que vous créez deviendront celles définies pour le compte à partir duquel l'image a été créée'''. De façon générale, il est difficile de revenir aux permissions qu'il faut et donc, dépendant du contenu de l'image, il pourrait être impossible de la mettre à jour par la suite.

Par exemple, les commandes pour les images Debian et Ubuntu <code>dpkg</code>, <code>apt-get</code> et <code>apt</code> exigent les permissions ''root'' pour installer et mettre à jour des paquets. Si vous prévoyez devoir éventuellement installer ou mettre à jour des logiciels, créez votre image dans un système Linux où vous avez les permissions ''root''. 

Remarque : les images créées sur votre ordinateur personnel doivent être téléchargées sur la grappe pour que vous puissiez les utiliser.

====Erreur de ''build'' avec une distribution Linux====
Avec certaines distributions, vous pourriez recevoir cette erreur même si la mémoire est suffisante.

<source>$ WARNING: 'nodev' mount option set on /tmp, it could be a source of failure during build process
$FATAL: no memory left on device</source>

Plusieurs distributions Linux récentes utilisent un système de fichiers en mémoire, ce qui pourrait limiter la taille d'un conteneur que vous voudriez construire.
Pour plus d'information, voir [https://sylabs.io/guides/3.6/user-guide/build_env.html#temporary-folders la documentation Singularity].

Si c'est le cas, vous pouvez résoudre le problème en configurant la variable d'environnement SINGULARITY_TMPDIR pour qu'elle pointe vers un fichier du système de fichiers.

<source>$ SINGULARITY_TMPDIR="disk/location" singularity build IMAGE_NAME.sif docker://DOCKER-IMAGE-NAME</source>

===Créer une image sur une de nos grappes===

Puisqu'il vous est impossible d'avoir les permissions <code>sudo</code> sur nos grappes, prenez connaissance de l'avertissement au paragraphe précédent. Les images peuvent être créées sur toutes nos grappes et sur les ordinateurs pour la visualisation (<code>gra-vdi.computecanada.ca</code> en date de février 2020). Veuillez tenir compte des particularités suivantes :
* sur <code>beluga.computecanada.ca</code>, connectez-vous avec [[SSH/fr|SSH]] et utilisez un nœud de connexion pour créer vos images;
* sur <code>cedar.computecanada.ca</code>, connectez-vous avec [[SSH/fr|SSH]] et créez vos images avec une tâche interactive; n'utilisez pas un nœud de connexion;
* sur <code>graham.computecanada.ca</code>, connectez-vous avec [[SSH/fr|SSH]] et utilisez un nœud de connexion pour créer vos images;
* sur <code>gra-vdi.computecanada.ca</code>, connectez-vous avec [[VNC/fr|VNC]] et utilisez une fenêtre de terminal pour créer vos images;
* sur <code>niagara.computecanada.ca</code>, connectez-vous avec [[SSH/fr|SSH]] et utilisez un nœud de connexion pour créer vos images;
** '''IMPORTANT :''' Ne créez pas de lien avec <code>/localscratch</code> qui n'existe pas sur Niagara.
L'option à privilégier est d'utiliser <code>gra-vdi.computecanada.ca</code>. Dans les autres cas, nous observons les difficultés suivantes :
* <code>beluga</code>, <code>graham</code> et <code>niagara</code>
** il y a un maximum de mémoire RAM pouvant être utilisé avec les nœuds de connexion et
** pas d'accès à l'internet avec les nœuds de calcul.
* <code>cedar</code>:
** les nœuds de connexion ne peuvent pas être utilisés et
** comme il est très difficile de prévoir combien de mémoire RAM est nécessaire avec les nœuds de calcul, une erreur pourrait survenir; si c'est le cas, quittez la tâche interactive et essayez de nouveau avec plus de mémoire.

===Créer une image avec DockerHub et Dockerfile ===

Le [https://hub.docker.com/ site Docker] offre une interface de recherche pour identifier des images et exige parfois une authentification pour télécharger des images. Si vous obtenez des erreurs comme
* <code>requested access to the resource is denied</code>
* <code>unauthorized: authentication required</code>
il est possible que
* votre URL Docker URL est incorrect '''et/ou'''
** Remarque : pour vérifier l'URL, utilisez [https://hub.docker.com/ Docker Hub] et cherchez l'image que vous voulez.
* vous devez vous [https://sylabs.io/guides/3.7/user-guide/singularity_and_docker.html?highlight=docker_password#authentication-via-interactive-login authentifier avec Docker] pour télécharger l'image.
** par exemple, il faut ajouter <code>--docker-login</code> après les commandes <code>build</code> ou <code>pull</code>.

Si par exemple l’URL du conteneur est <tt>docker://ubuntu</tt>, téléchargez le conteneur avec
<source lang="console">$ singularity build myubuntuimage.sif docker://ubuntu</source>

Cette commande fonctionne sur un nœud de calcul de Cedar, mais pas avec Béluga ou Graham parce que leurs nœuds de calcul n'ont pas d'accès à l'internet. Nous ne recommandons pas de construire de grandes images Singularity sur les nœuds de connexion parce que ceci affecterait les autres utilisateurs et échouerait probablement en raison de l'utilisation intensive des CPU et de la mémoire vive. Les directives suivantes peuvent résoudre le problème. 
# Téléchargez une image Docker sans la convertir à Singularity. Pour ce faire, vous pouvez utiliser l'outil [https://raw.githubusercontent.com/moby/moby/master/contrib/download-frozen-image-v2.sh download-frozen-image] du [https://github.com/moby/moby/ projet moby]. Ceci utilise peu de ressources de calcul et peut se faire sur un nœud de copie ou un nœud de connexion. 
# Convertissez l'image Docker que vous avez téléchargée en une image Singularity. Ceci utilise beaucoup de ressources de calcul et devrait se faire sur un nœud de calcul et avec une allocation de mémoire et de CPU convenable.

En exemple, nous allons télécharger une image Singularity pour le paquet [https://gqcg.github.io/GQCP/ GQCP].

Sur un nœud de copie ou un nœud de connexion, téléchargez l'image Docker.
<source>$ cd ~/scratch
$ wget https://raw.githubusercontent.com/moby/moby/master/contrib/download-frozen-image-v2.sh
$ sh download-frozen-image-v2.sh gqcp gqcg/gqcp:latest
$ cd gqcp && tar cf ../gqcp.tar * && cd ..</source>

Lancez une [[Running_jobs/fr#Tâches_interactives|tâche interactive]].
<source>$ cd ~/scratch
$ salloc --mem-per-cpu=2000 --cpus-per-task=4 --time=2:0:0</source>

Sur le nœud de calcul alloué, construisez l'image Singularity.
<source>$ module load singularity
$ singularity build gqcp.sif docker-archive://gqcp.tar</source>

Vous pouvez aussi utiliser un Dockerfile pour créer une image Singularity.
* Créez d'abord une image Docker avec un document Dockerfile dans une instance ou sur votre machine Linux où vous avez les permissions <tt>sudo</tt>. Dans le répertoire où se trouve le Dockerfile, lancez la commande <tt>sudo docker build -t CC:latest .</tt>; le paramètre <tt>.</tt> demande à Docker de chercher le Dockerfile dans le répertoire courant. La commande crée une image Docker nommée ''CC'' et lui assigne une balise ayant la valeur ''latest''; Docker assigne cette valeur par défaut à une image et même si vous n'utilisez pas cette balise, sa valeur par défaut sera ''latest''. 
* La seconde étape est d'utiliser l'image Docker que nous avons créée ci-dessus comme source pour Singularity. Dans cet exemple, l'image Singularity ''cc_image_latest.sif'' est créée à partir de l'image Docker ''CC:latest''.<source>sudo singularity build cc_image_latest.sif docker-daemon://CC:latest</source>
Il n'est pas nécessaire de spécifier le chemin pour l'image Docker puisque le démon Docker va automatiquement chercher l'image dans le registre Docker, mais il faut s'assurer d'utiliser le bon nom d'image et la bonne valeur pour la balise.

===Créer une image personnalisée avec l'indicateur <tt>sandbox</tt>===

L'indicateur <tt>sandbox</tt> vous permet de créer un conteneur à l'intérieur d'un répertoire où l'écriture est permise, ce qui permet de facilement modifier les conteneurs existants.
<source>
$ singularity build --sandbox IMAGE_NAME/ docker://DOCKER-IMAGE-NAME
</source>
L'indicateur <tt>--writable</tt> permet d'apporter des changements dans le conteneur.
<source>
$ singularity shell --writable IMAGE_NAME/ 
</source>
Le répertoire servant de bac à sable peut être converti en un fichier  <tt>sif</tt> avec la commande <tt>build</tt> comme suit
<source>
$ singularity build production.sif IMAGE_NAME/ 
</source>

===Utiliser la commande sudo===

Dans la documentation de Singularity sur [https://sylabs.io/guides/3.5/user-guide/build_a_container.html comment construire un conteneur], on utilise la commande <code>sudo</code> parce que la commande <code>build</code> requiert souvent les permissions ''root'' de l’utilisateur racine (superutilisateur). Comme nos utilisateurs n’ont pas ce niveau de permissions, la commande <code>sudo</code> ne peut pas être utilisée.
Vous n’avez généralement pas besoin d’un accès <code>sudo</code> si vous construisez une image préconstruite à partir de Singularity ou de Docker Hub. Si vous avez besoin des privilèges ''root'' pour construire une image, vous pouvez demander l’intervention du soutien technique ou encore installer Linux et Singularity sur votre propre ordinateur.

Il est fort possible que vous n’ayez pas besoin d’utiliser la commande <code>sudo</code> avec votre image. Voici ce qui se produira si elle n’est pas utilisée :
* Singularity émettra un avertissement indiquant que l’image créée ne fonctionnera pas; il ne s’agit toutefois que d’un avertissement et l’image sera quand même créée.
* Toutes les permissions pour le système de fichiers seront réduites aux permissions de l’utilisateur et du groupe Linux qui exécute <code>singularity build</code>, habituellement l’utilisateur et le groupe qui ont servi à la connexion.

Habituellement, vous n’avez pas à vous soucier de conserver les permissions à moins que
* vous ayez à régulièrement mettre à jour et reconfigurer le contenu de l’image et
* que les outils pour mettre à jour et reconfigurer le contenu de l’image '''exigent''' que les permissions ne soient pas modifiées.

Il est facile de mettre à jour ou d’installer de nouveaux logiciels avec plusieurs distributions Linux à l’aide de commandes comme
* <code>apt-get update && apt-get upgrade</code>
* <code>apt-get install some-software-package</code>
* <code>yum install some-software-package</code>
* <code>dnf install some-software-package</code>
* etc.
Il est possible que ces commandes et d’autres ne s’exécutent correctement que si les permissions des systèmes de fichiers sont conservées.

La création d’une image pourrait ne pas se faire en raison de certaines restrictions du nœud avec lequel vous travaillez; en particulier, c’est le cas des nœuds de connexion. Si vous avez besoin d’assistance pour créer une image Singularity, contactez le [[Technical support/fr|soutien technique]].

==Utiliser Singularity==

'''NOTE''' : Nous abordons ici l’utilisation de Singularity sans tenir compte de Slurm qui fait l’ordonnancement des tâches interactives ou en lots; pour des renseignements à ce sujet, consultez [[Running jobs/fr|Exécuter des tâches]].

Sauf quand vous créez votre image Singularity, vous ne pouvez pas utiliser la commande <tt>sudo</tt> pour exécuter des applications dans votre image. Il y a différentes façons d’exécuter ces applications :
# exécuter les commandes interactivement dans une session Singularity;
# exécuter une commande unique qui s’arrête lorsqu’elle est complétée;
# exécuter une instance conteneur pour exécuter des démons.

===Exécuter les commandes interactivement===

Pour des renseignements sur l’utilisation de la commande pour l’interpréteur Singularity, utilisez

<source lang="console">$ singularity shell --help</source>

Dans l’exemple suivant avec le conteneur <code>myimage.simg</code>,

<source lang="console">$ singularity shell -B /home -B /project -B /scratch -B /localscratch myimage.simg</source>

le résultat serait de
* faire un ''bind mount'' de <code>/home</code> pour que tous les répertoires ''home'' soient accessibles (dépendant des permissions associées à votre compte);
* faire un ''bind mount'' de <code>/project</code> pour que tous les répertoires ''project'' soient accessibles (dépendant des permissions associées à votre compte);
* faire un ''bind mount'' de <code>/scratch</code>  pour que le répertoire ''scratch'' soit accessible (dépendant des permissions associées à votre compte);
* faire un ''bind mount'' de <code>/localscratch</code> pour que le répertoire ''localscratch'' soit accessible (dépendant des permissions associées à votre compte);
* exécuter un interpréteur  (par exemple <code>/bin/bash</code>)

Si cette commande réussit, vous pourrez exécuter des commandes interactivement à partir de votre conteneur en ayant accès à vos fichiers dans ''home'', ''project'', ''scratch'' et ''localscratch''.

NOTE : Lorsque vous avez terminé, entrez ''exit''.

Dans certains cas, vous ne voudrez pas que les variables d'environnement soient polluées par l’interpréteur; utilisez donc un environnement ''propre'' en ajoutant l’option <code>-e</code> comme suit

<source lang="console">$ singularity shell -e -B /home -B /project -B /scratch -B /localscratch myimage.simg</source>

Sachez toutefois que vous devrez peut-être définir certaines variables de l’environnement de l’interpréteur, par exemple <code>$USER</code>.

Enfin, si vous utilisez Singularity interactivement sur votre propre ordinateur, vous devez vous assurer de satisfaire les conditions suivantes pour que les modifications apportées à l’image soient enregistrées sur le disque :

* utiliser une image ''sandbox'' Singularity (c’est-à-dire utiliser un répertoire et non le fichier en lecture seule .simg)
* utiliser l'option <code>-w</code> et
* utiliser <code>sudo</code>.

Par exemple, créez d’abord votre image ''sandbox'' avec

<source lang="console">$ sudo singularity build -s myimage-dir myimage.simg</source>

puis communiquez interactivement avec Singularity.

<source lang="console">$ sudo singularity shell -w myimage-dir</source>

Lorsque vous avez terminé, créez ou mettez à jour le fichier simg avec

<source lang="console">$ sudo singularity build myimage-new.simg myimage-dir/</source>

et téléversez myimage-new.simg sur une grappe pour pouvoir l’utiliser.

===Exécuter une commande unique===

Pour soumettre une tâche qui fait appel à des commandes dans un conteneur Singularity, il faut utiliser les commandes Singularity <code>exec</code> ou <code>run</code>.
* la commande <code>exec</code> ne nécessite aucune configuration

* avec la commande <code>run</code>, il faut configurer une application à l’intérieur d’un fichier de recette Singularity; ce sujet n’est pas abordé ici.

Les options pour la commande <code>exec</code> sont presque identiques à celles de la commande <code>shell</code>, par exemple

<source lang="console">$ singularity exec --help</source>

Lorsqu’il ne s’agit pas d’une demande d’assistance, <code>exec</code> exécute la commande spécifiée dans le conteneur et quitte ensuite le conteneur, par exemple

<source lang="console">$ singularity exec -B /home -B /project -B /scratch -B /localscratch myimage.simg ls /</source>

qui retourne le contenu du répertoire racine dans le conteneur. Notez que la version de <code>ls</code> est celle qui est installée dans le conteneur; si par exemple <code>gcc</code> de GCC était installé dans le conteneur myimage.simg, la commande suivante

<source lang="console">$ singularity exec -B /home -B /project -B /scratch -B /localscratch myimage.simg gcc -v</source>

retournerait les renseignements sur la version de ce qui est installé dans le conteneur, alors qu’à l’invite de l’interpréteur usuel,

<source lang="console">$ gcc -v</source>

retournerait la version de GCC chargée à ce moment sur la grappe.


Pour exécuter une commande unique de l’intérieur de votre conteneur Singularity, la commande <code>exec</code> est suffisante. N’oubliez pas de faire un [[#Bind Mount|''bind mount'']] des répertoires dont vous aurez besoin pour que votre tâche soit bien exécutée.

Singularity accepte aussi les variables d'environnement définies par l'utilisateur avec l'indicateur <code>--env-file</code>. En argument, nous passons à cet indicateur le chemin du fichier dans lequel sont définies les variables à utiliser dans le contexte Singularity. L'indicateur <code>--env-file</code> est particulièrement utile dans les cas où nous voulons utilliser l'indicateur <code>-e</code> avec <code>singularity exec</code> pour obliger un environnement ''propre''.

Par exemple, pour utiliser la variable d'environnement <code>PYSPARK_SUBMIT_ARGS</code> dans le contexte Singularity, il faut créer un fichier (ici <code>envfile</code>) dans lequel la variable <code>PYSPARK_SUBMIT_ARGS</code> est définie. Il est possible de définir plusieurs variables dans le même fichier. 
 
<source lang="console">PYSPARK_SUBMIT_ARGS='--driver-memory 96g  --driver-java-options "-verbose:gc  -XX:+UseSerialGC  -XX:-UseGCOverheadLimit" pyspark-shell'</source>

Nous passons ensuite le chemin du fichier à la commande Singularity avec l'indicateur <code>--env-file</code>. 

<source lang="console">$ singularity exec --env-file envfile  myimage.simg gcc -v</source>

Dans l'exemple ci-dessus, nous supposons que <code>envfile</code> se trouve au même endroit où la commande Singularity a été exécutée; c'est pourquoi nous avons passé uniquement le nom du ficher plutôt que le chemin vers ce fichier.


===Exécuter des instances de conteneurs===

Pour exécuter des démons et des processus en arrière-plan dans un conteneur, n’utilisez pas la commande <code>exec</code>, mais plutôt les commandes Singularity '''instance.start''' et '''instance.stop''' pour créer et supprimer les sessions (les instances de conteneurs). En utilisant des sessions, Singularity s’assure que vos applications exécutées dans l’instance sont terminées quand la tâche se termine, peu importe la raison.

Pour démarrer une instance de session, lancez la commande '''instance.start''' suivie du nom de l’image (ici <code>myimage.simg</code>) et du nom de la session (ici <code>quadrat5run</code>).

<source lang="console">$ singularity instance.start myimage.simg quadrat5run</source>

La commande '''instance.stop''' met fin à la session et à toutes les applications qui y sont associées.

<source lang="console">$ singularity instance.stop myimage.simg quadrat5run</source>

En tout temps, vous pouvez voir la liste des sessions en cours avec

<source lang="console">$ singularity instance.list</source>

qui fournit le nom du démon, son PID et le chemin pour l’image du conteneur.

Lorsqu’une session est en cours, les applications peuvent être exécutées avec les commandes Singularity <code>shell</code>, <code>exec</code> ou <code>run</code> en indiquant le nom de l’image suivi du préfixe '''instance://''' accolé au nom de la session.

<source lang="console">$ singularity instance.start mysessionname
$ singularity exec myimage.simg instance://mysessionname ps -eaf
$ singularity shell myimage.simg instance://mysessionname 
nohup find / -type d >dump.txt
exit
$ singularity exec myimage.simg instance://mysessionname ps -eaf
$ singularity instance.stop mysessionname
</source>

===Bind mount===

Par défaut, une application exécutée dans un conteneur Singularity ne voit que les fichiers dans l’image du conteneur et ceux dans le répertoire courant. Les tâches Singularity doivent donc faire le ''bind mount'' des systèmes de fichiers dans lesquels se trouvent les fichiers avec l’option <code>-B</code> aux commandes <code>shell</code>, <code>exec</code> ou <code>run</code>.

<source lang="console">$ singularity shell -B /home -B /project -B /scratch -B /localscratch myimage.simg</source>
<source lang="console">$ singularity exec -B /home -B /project -B /scratch -B /localscratch myimage.simg ls /</source>
<source lang="console">$ singularity run -B /home -B /project -B /scratch -B /localscratch:/temp myimage.simg some-program</source>

Ces commandes font un ''bind mount'' des systèmes de fichiers de l’image de conteneur <code>myimage.simg</code>  :
* <code>/home</code> pour que tous les répertoires ''home'' soient accessibles (dépendant des permissions associées à votre compte);
* <code>/project</code> pour que tous les répertoires ''project'' soient accessibles (dépendant des permissions associées à votre compte);
* <code>/scratch</code> pour que le répertoire ''scratch'' soit accessible (dépendant des permissions associées à votre compte);
* <code>/localscratch</code> pour que le répertoire ''localscratch'' soit accessible (dépendant des permissions associées à votre compte).
Dans le dernier énoncé, nous voyons comment modifier le nom du ''mount'' qui est visible dans le conteneur Singularity pour que <code>/localscratch</code> soit vu comme étant <code>/temp</code> dans le conteneur. Ceci peut être utile quand vous voulez utiliser un espace de stockage comme <code>$SLURM_TMPDIR</code> qui est directement attaché au nœud de calcul et qui est disponible dans une tâche. Le programme peut lui-même faire abstraction des détails en utilisant toujours <code>/temp</code>. 

Dans la plupart des cas, il n’est pas recommandé de monter directement chacun des répertoires pour éviter des problèmes d’accès; montez plutôt le répertoire racine du système de fichiers, tel que décrit plus haut.

==Problèmes connus pour le CHP ==

===Applications MPI dans un conteneur===

Si vous utilisez des applications MPI, rien de particulier ne doit être fait pour les tâches utilisant un seul nœud.

Pour utiliser plusieurs nœuds, vous devez :

* vous assurer que votre application MPI est compilée avec la version OpenMPI qui est installée dans votre conteneur Singularity;
** idéalement, cette version OpenMPI est 3 ou 4; la version 2 pourrait ou non fonctionner; la version 1 ne fonctionnera pas; 
* vous assurer que MPI dans le conteneur peut utiliser la même bibliothèque pour l'interface de gestion des processus que celle de la version MPI sur la grappe, par exemple PMI-2 ou PMIx;
* vous assurer que le script de votre tâche Slurm utilise <code>srun</code> pour exécuter l'application MPI et que <code>srun</code> utilise une bibliothèque pmi qui est supportée par l'implémentation MPI dans le conteneur; n'utilisez pas <code>mpirun</code> ou <code>mpiexec</code>, par exemple
<source lang="bash">
srun --mpi=pmi2 singularity exec /path/to/your/singularity/image.sif /path/to/your-program
</source>MPI dans le conteneur ne supporte que PMI-2 (utilisez <code>--mpi=pmix</code> pour PMIx);
* vous assurer que le script de votre tâche ne contient aucune commande pour charger un module; 
* installer dans votre conteneur le paquet <code>slurm-client</code> de votre distribution pour pouvoir interagir avec l'ordonnanceur Slurm;
* avant de soumettre la tâche avec <code>sbatch</code>, dans l'interpréteur (''shell'') CC, chargez les modules suivants :
** <code>singularity</code>
** <code>openmpi</code> (il n'est pas nécessaire que la version corresponde à la version de OpenMPI dans le conteneur; idéalement, utilisez les versions 3 ou 4; la version 2 pourrait ou non fonctionner; la version 1 ne fonctionnera pas).

Enfin, assurez-vous qu'un paquet de réseautique haute performance soit installé dans votre image :
* installez libpsm2 si le superordinateur utilise OmniPath, 
* installez UCX si le superordinateur utilise Infiniband.

Pour connaître les bibliothèques qui ont servi à la configuration de MPI sur la grappe, utilisez
* <code> ompi_info --config</code> pour OpenMPI
* <code> mpiexec -info</code> pour MPICH
Ces commandes indiquent les bibliothèques que vous utiliser pour installer MPI dans le conteneur Singularity.

=== Utiliser CUDA sur une grappe === 

Si vous utilisez des programmes qui utilisent la bibliothèque CUDA, assurez-vous que CUDA est installé dans votre conteneur Singularity.

Pour que CUDA fonctionne, il faut ajouter l'indicateur <tt>--nv</tt>.

<source>
$ srun singularity run --nv container-name.sif [job to do]
</source>

==Changer les répertoires Singularity par défaut==

Vous pouvez changer le répertoire temporaire et le répertoire de mise en cache en définissant ces variables d'environnement avant de lancer Singularity :

* <code>SINGULARITY_CACHEDIR</code> : répertoire pour l’écriture des fichiers temporaires, incluant ceux créés à la construction de fichiers image SquashFS,
* <code>SINGULARITY_TMPDIR</code> : répertoire pour le téléchargement et la mise en cache des fichiers.

Dans cet exemple, on demande à Singularity d’utiliser l’espace <tt>/scratch</tt> pour les fichiers temporaires et la mise en cache.

<source lang="console">$ mkdir -p /scratch/$USER/singularity/{cache,tmp}
$ export SINGULARITY_CACHEDIR="/scratch/$USER/singularity/cache"
$ export SINGULARITY_TMPDIR="/scratch/$USER/singularity/tmp"
</source>

Ces commandes doivent être exécutées avant de lancer Singularity.

=Voir aussi=
Présentation faite par Paul Preney le 14 février 2018 ː
* [https://www.sharcnet.ca/help/index.php/Online_Seminars dans la liste des séminaires web SHARCNET]
* [https://www.youtube.com/watch?v=C4va7d7GxjM vidéo YouTube]

=Références=
<references/>

[[Category:Pages with video links]]