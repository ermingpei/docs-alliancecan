<languages />


[[https://developer.nvidia.com/cuda-toolkit CUDA]] <ref>Marque de commerce de NVIDIA.</ref>est une plateforme de calcul parallèle et un modèle de programmation développé par NVIDIA pour des calculs généraux utilisant le GPU.

On peut voir CUDA comme étant un ensemble de bibliothèques et de compilateurs C, C++ et Fortran qui permettent de créer des programmes pour les GPU. Pour d'autres outils de programmation pour GPU, consultez le [[OpenACC Tutorial/fr|Tutoriel OpenACC]].

== Un exemple simple ==

===Compilation===
Nous faisons exécuter ici du code créé avec le compilateur CUDA C/C++ <code>nvcc</code>. Ce même exemple plus détaillé se trouve à la page [[CUDA tutorial/fr|Tutoriel CUDA]].

Chargez d'abord le [[Utiliser des modules|module]] CUDA.
<source lang="console">
$ module purge
$ module load cuda
</source>

Dans cet exemple, nous additionnons deux nombres. Sauvegardez le fichier sous <code>add.cu</code>; <i>le suffixe <code>cu</code> est important</i>. 

{{File  
  |name=add.cu
  |lang="c++"
  |contents=
#include <iostream>

__global__ void add (int *a, int *b, int *c){
  *c = *a + *b;
}

int main(void){
  int a, b, c;
  int *dev_a, *dev_b, *dev_c;
  int size = sizeof(int);
  
  //  allocate device copies of a,b, c
  cudaMalloc ( (void**) &dev_a, size);
  cudaMalloc ( (void**) &dev_b, size);
  cudaMalloc ( (void**) &dev_c, size);
  
  a=2; b=7;
  //  copy inputs to device
  cudaMemcpy (dev_a, &a, size, cudaMemcpyHostToDevice);
  cudaMemcpy (dev_b, &b, size, cudaMemcpyHostToDevice);
  
  // launch add() kernel on GPU, passing parameters
  add <<< 1, 1 >>> (dev_a, dev_b, dev_c);
  
  // copy device result back to host
  cudaMemcpy (&c, dev_c, size, cudaMemcpyDeviceToHost);
  std::cout<<a<<"+"<<b<<"="<<c<<std::endl;
  
  cudaFree ( dev_a ); cudaFree ( dev_b ); cudaFree ( dev_c );
}
}}

Compilez le programme avec <code>nvcc</code> pour créer l'exécutable <code>add</code>.
<source lang="console">
$ nvcc add.cu -o add
</source>

===Soumission de tâches===
Pour exécuter le programme, créez le script Slurm ci-dessous. Assurez-vous de remplacer <code>def-someuser</code> par votre nom de compte (voir [[Running_jobs/fr#Comptes_et_projets|Comptes et projets]]). Pour les détails sur l'ordonnancement, consultez [[Using GPUs with Slurm/fr|Ordonnancement Slurm des tâches avec GPU]]. 
{{File
  |name=gpu_job.sh
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-someuser
#SBATCH --gres=gpu:1              # Number of GPUs (per node)
#SBATCH --mem=400M                # memory (per node)
#SBATCH --time=0-00:10            # time (DD-HH:MM)
./add #name of your program
}}

Soumettez la tâche à l'ordonnanceur. 
<source lang="console">
$ sbatch gpu_job.sh
Submitted batch job 3127733
</source>
Pour plus d'information sur la commande <code>sbatch</code>, l'exécution et le suivi des tâches, consultez [[Running jobs/fr|Exécuter des tâches]].

Le fichier en sortie sera semblable à ceci&nbsp;ː
<source lang="console">
$ cat slurm-3127733.out
2+7=9
</source>
Sans GPU, le résultat serait semblable à <code>2+7=0</code>. 

=== Lier des bibliothèques ===
Si votre programme doit établir des liens avec des bibliothèques incluses avec CUDA, par exemple [https://developer.nvidia.com/cublas cuBLAS], compilez avec ces indicateurs&nbsp;:
<source lang="console">
nvcc -lcublas -Xlinker=-rpath,$CUDA_PATH/lib64
</source>

Voyez le [[CUDA tutorial/fr|Tutoriel CUDA]] pour plus de détails sur cet exemple et pour savoir comment utiliser le parallélisme avec les GPU.

== Dépannage ==

=== Attribut <i>compute capability</i> ===

NVIDIA utilise le terme <i>compute capability</i> pour désigner un des attributs des dispositifs GPU.

Parfois nommé <i>SM version</i> (SM pour <i>Streaming Multiprocessor</i>), il s'agit d'un numéro de version qui identifie certaines fonctionnalités d'un GPU. Cet attribut est utilisé à l'exécution d'une application pour déterminer les caractéristiques matérielles et/ou les instructions disponibles pour un GPU particulier; pour plus d'information, voir [https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability CUDA Toolkit Documentation, section 2.6].

Les messages d’erreur suivants sont causés par un problème en rapport avec cet attribut.

<pre>
nvcc fatal : Unsupported gpu architecture 'compute_XX'
</pre>

<pre>
no kernel image is available for execution on the device (209)
</pre>

L'ajout d'un indicateur dans l'appel <code>nvcc</code> pourrait résoudre ces problèmes.

<pre>
-gencode arch=compute_XX,code=[sm_XX,compute_XX]
</pre>

Si vous utilisez <code>cmake</code>, l'indicateur serait

<pre>
cmake .. -DCMAKE_CUDA_ARCHITECTURES=XX
</pre>

où XX est la valeur de <i>compute capability</i> pour le GPU NVIDIA qui sera utilisé pour exécuter votre application. Pour connaître ces valeurs, voyez le [[Using GPUs with Slurm/fr#GPU_disponibles | tableau GPU disponibles]].

<b>Par exemple</b>, si votre code sera exécuté sur un nœud A100 de Narval, <i>compute capability</i> a la valeur de 80 et l'indicateur à utiliser lors de la compilation avec <code>nvcc</code> est

<pre>
-gencode arch=compute_80,code=[sm_80,compute_80]
</pre>

L'indicateur pour <code>cmake</code> est

<pre>
cmake .. -DCMAKE_CUDA_ARCHITECTURES=80
</pre>