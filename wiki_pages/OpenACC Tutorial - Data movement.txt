<languages />

{{Objectives
|title=<translate><!--T:1-->
Learning objectives</translate>
|content=
<translate>
<!--T:2-->
* Understand what are data locality and data movement
* Understand what are structured and unstructured data clauses
* Learn how to move data explicitly
* Learn how to compile and run OpenACC code with data movement directives
</translate>
}}

<translate>
== Making Data Management Explicit == <!--T:3-->

<!--T:4-->
[[File:Intro-DM.png|thumbnail|200px|Data management with Unified Memory|right  ]]
We used CUDA Unified Memory to simplify the first steps in accelerating our code.
This made the process simple, but it also made the code not portable:
* PGI-only: –ta=tesla:managed flag
* NVIDIA-only: CUDA Unified Memory
Explicitly managing data will make the code portable and may improve performance.

== Structured Data Regions == <!--T:5-->
The <tt>data</tt> directive defines a region of code in which GPU arrays remain on the GPU and are shared among all kernels in that region.
Here is an example of defining the structured data region with data directives:
</translate>

<syntaxhighlight lang="cpp" line highlight="1,6">
#pragma acc data
{
#pragma acc parallel loop ...
#pragma acc parallel loop
...
}
</syntaxhighlight> 
<translate>
<!--T:6-->
another example:
</translate>
<syntaxhighlight lang="cpp" line highlight="1,6">
!$acc data
!$acc parallel loop
...
!$acc parallel loop
...
!$acc end data
</syntaxhighlight> 
{{Callout
|title=<translate><!--T:7-->
Data locality</translate>
|content=
<translate>
<!--T:8-->
Arrays used within the data region will remain on the GPU until the end of the data region.
</translate>
}}

<translate>
== Unstructured Data == <!--T:9-->
We sometimes encounter a situation where scoping does not allow the use of normal data regions (e.g. when using constructors or destructors). 
=== Directives ===
In those cases, we use unstructured data directives:
* '''enter data''' - defines the start of an unstructured data lifetime
** clauses : '''copyin(list)''', '''create(list)'''
* '''exit data''' - defines the end of an unstructured data lifetime
** clauses: '''copyout(list)'', '''delete(list)'''
Below is the example of using the unstructured data directives in the code:
</translate>

<syntaxhighlight lang="cpp" line highlight="1,3">
#pragma acc enter data copyin(a)
...
#pragma acc exit data delete(a)
</syntaxhighlight>

<translate>
=== C++ Classes === <!--T:10-->
What is the advantage of having unstructured data clauses? In fact, unstructured data clauses enable OpenACC to be used in C++ classes.
Moreover, unstructured data clauses can be used whenever data is allocated and initialized in a different piece of code than where it is freed (e.g. Fortran modules).
</translate>
<syntaxhighlight lang="cpp" line highlight="4,5,8,9">
class Matrix { Matrix(int n) {
len = n;
v = new double[len];
#pragma acc enter data
                     create(v[0:len])
}
~Matrix() {
#pragma acc exit data 
                     delete(v[0:len])
};
</syntaxhighlight>

<translate>
=== Data Clauses === <!--T:11-->
* '''copyin(list)''' - Allocates memory on GPU and copies data from host to GPU when entering region.
* '''copyout(list)''' - Allocates memory on GPU and copies data to the host when exiting region.
* '''copy(list)''' - Allocates memory on GPU and copies data from host to GPU when entering region and copies data to the host when exiting region. (Structured Only)
* '''create(list)''' - Allocates memory on GPU but does not copy.
* '''delete(list)''' - Deallocate memory on the GPU without copying. (Unstructured Only)
* '''present(list)''' - Data is already present on GPU from another containing data region.

=== Array Shape === <!--T:12-->
Sometimes, the compiler cannot determine the size of arrays. Therefore, one have to explicitly specify the size with data clauses and array "shape". 
Here is an example of array shape in C:
</translate>
<syntaxhighlight lang="cpp" line highlight="1">
#pragma acc data copyin(a[0:nelem]) copyout(b[s/4:3*s/4])
</syntaxhighlight>

<translate>
<!--T:13-->
In Fortran it will look like this:
</translate>
<syntaxhighlight lang="cpp" line highlight="1">
!$acc data copyin(a(1:end)) copyout(b(s/4:3*s/4))
</syntaxhighlight>

<translate>
== Explicit Data Movement: Examples == <!--T:14-->
=== Copy In Matrix ===
In the following example we allocate and initialize the matrix first. Then copy it to the device. The copy procedure is done in two steps:
# Copy the structure of the matrix.
# Copy its members. 
</translate>
<syntaxhighlight lang="cpp" line highlight="10,11">
void allocate_3d_poisson_matrix(matrix &A, int N) { 
   int num_rows=(N+1)*(N+1)*(N+1);
   int nnz=27*num_rows;
   A.num_rows=num_rows;
   A.row_offsets = (unsigned int*) \ malloc((num_rows+1)*sizeof(unsigned int));
   A.cols = (unsigned int*)malloc(nnz*sizeof(unsigned int));
   A.coefs = (double*)malloc(nnz*sizeof(double)); // Initialize Matrix
   A.row_offsets[num_rows]=nnz;
   A.nnz=nnz;
   #pragma acc enter data copyin(A)
   #pragma acc enter data copyin(A.row_offsets[:num_rows+1],A.cols[:nnz],A.coefs[:nnz])
}
</syntaxhighlight>

<translate>

=== Delete Matrix === <!--T:15-->
In this example, in order to free the device memory we first remove the matrix from the device, then issue the free instructions. Again, this is done in two steps (in reverse order):
# Delete the members.
# Delete the structure.
</translate>
<syntaxhighlight lang="cpp" line highlight="5,6">
void free_matrix(matrix &A) {
   unsigned int *row_offsets=A.row_offsets; 
   unsigned int * cols=A.cols;
   double * coefs=A.coefs;
   #pragma acc exit data delete(A.row_offsets,A.cols,A.coefs) 
   #pragma acc exit data delete(A)
   free(row_offsets); 
   free(cols); 
   free(coefs);
}
</syntaxhighlight>

<translate>

=== The <tt>present</tt> Clause === <!--T:16-->
When managing the memory at a higher level, it’s necessary to inform the compiler that data is already present on the device.
Local variables should still be declared in the function where they’re used.
</translate>
<syntaxhighlight lang="cpp" line highlight="2,8">
function main(int argc, char **argv) {
#pragma acc data copy(A) {
    laplace2D(A,n,m);
}
}
...
function laplace2D(double[N][M] A,n,m){
   #pragma acc data present(A[n][m]) create(Anew)
   while ( err > tol && iter < iter_max ) {
      err=0.0;
      ...
   }
}
</syntaxhighlight>

{{Callout
|title=<translate><!--T:17-->
Use <tt>present</tt> when possible.</translate>
|content=
<translate>
<!--T:18-->
High-level data management and the <tt>present</tt> clause are often critical to good performance.
</translate>
}}

<translate>
<!--T:19-->
In our next example, we inform the compiler in the compute region of the code that our data is already present:
</translate>
<syntaxhighlight lang="cpp" line highlight="1,2">
#pragma acc kernels \
present(row_offsets,cols,Acoefs,xcoefs,ycoefs)
{
   for(int i=0;i<num_rows;i++) {
      double sum=0;
      int row_start=row_offsets[i];
      int row_end=row_offsets[i+1]; 
      for(int j=row_start;j<row_end;j++) {
         unsigned int Acol=cols[j]; 
         double Acoef=Acoefs[j]; 
         double xcoef=xcoefs[Acol]; 
         sum+=Acoef*xcoef;
      }
   ycoefs[i]=sum; 
   }
}
</syntaxhighlight>

<translate>

=== Compiling and Running with Explicit Memory Management === <!--T:20-->
In order to rebuild the code without managed memory change '''-ta=tesla:managed''' to '''-ta-tesla''' in the Makefile.

=== Update Directive === <!--T:21-->
In OpenACC it is possible to specify an array (or part of an array) that should be refreshed within the data region. In order to do so we use the <tt>update</tt> directive:
</translate>
<syntaxhighlight lang="cpp" line highlight="2,4">
do_something_on_device()
!$acc update self(a)   //  '''Copy "a" from GPU to CPU'''
do_something_on_host()
!$acc update device(a)  // '''Copy "a" from CPU to GPU'''
</syntaxhighlight>

<translate>
<!--T:22-->
In the following example we demonstrate the usage of the <tt>update</tt> directive. First, we modify a vector on the CPU (host), then copy it to the GPU (device):
</translate>

<syntaxhighlight lang="cpp" line highlight="4,5">
void initialize_vector(vector &v,double val) {
   for(int i=0;i<v.n;i++) 
      v.coefs[i]=val;   // '''Updating the vector on the CPU '''
   #pragma acc update 
      device(v.coefs[:v.n])    // '''Updating the vector on the GPU'''
}
</syntaxhighlight>

<translate>
=== Build and Run without Managed Memory === <!--T:23-->
Below we demonstrate the performance of the code with and without managed memory.
[[File:Benchmark-DM.png|thumbnail|300px|Benchmarking codes with and without managed memory|right  ]]
</translate>
<translate>
<!--T:24-->
In this example, several benchmarks that use OpenACC directives have been compiled with and without the '''-ta=tesla:managed''' option:
[[File:Benchmark2-DM.png|thumbnail|300px|Another benchark results |right  ]]
</translate>
<translate>
<!--T:25-->
The results indicate that some of these tests improve speed using managed memory, but probably due to the use of the pinned memory in the data transfers. Overall, the results suggest that data locality indeed works: when most of the operations are on the GPU and data stays on the GPU for a long time, the data movement does not play a significant role in the performance.








<!--T:27-->
{{Challenge
|title=
Challenge: Adding Data directives
|content=


<!--T:30-->
# Modify the code to use explicit data directives. You may use either the <tt>kernels</tt> or the <tt>parallel loop</tt> directives. The directories step2.* from the [https://github.com/calculquebec/cq-formation-openacc Github repository] contain the solution.
# Change your compiler flags to <tt>-ta=tesla</tt> (not managed)
# Check if you are getting the same results and performance as before.

<!--T:31-->
}}
</translate>
<translate>
<!--T:29-->
[[OpenACC Tutorial - Optimizing loops|Onward to the next unit: Optimizing loops]]<br>
[[OpenACC Tutorial|Back to the lesson plan]]
</translate>