{{Draft}}

ZFS is a combined [https://en.wikipedia.org/wiki/File_system file system] and [https://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux) logical volume manager] designed by [https://en.wikipedia.org/wiki/Sun_Microsystems Sun Microsystems]. ZFS can scale to very large file system sizes and supports compression.

ZFS greatly simplifies the process of increasing a filesystem size as required. The simpliest approach is to add new volumes to your VM and then add them to your ZFS filesystem to grow the size of your file system. This can be done while the filesystem is live and file IO is occuring on the filesystem.

=Installing ZFS=
<tabs>

<tab name="Ubuntu">

Starting with the image <code>Ubuntu-18.04-Bionic-x64-2018-09</code>

Ensure your package list is up-to-date and also do upgrades of your installed packages. While it isn't strictly nessacary to upgrade your installed packages it is a good idea.
<source lang="console">
[name@server]$ sudo apt-get update 
[name@server]$ sudo apt-get dist-upgrade -y
</source>

Next install ZFS.
<source lang="console">
[name@server]$ sudo apt-get install zfsutils-linux
</source>
</tab>

<tab name="CentOS">
Starting with the image <code>CentOS-7-x64-2018-09</code>

<source lang="console">
[name@server]$ sudo yum install http://download.zfsonlinux.org/epel/zfs-release.el7_5.noarch.rpm
...
Total size: 2.9 k
Installed size: 2.9 k
Is this ok [y/d/N]: y
...
</source>
hmm... this is looking strangely more complicated, see for example [https://linuxhint.com/install-zfs-centos7/]
</tab>

<tab name="Fedora">
Starting with the image <code>Fedora-Cloud-Base-29-1.2</code>

to be written!
</tab>

</tabs>

=Using ZFS=

==Creating a zpool==
<source lang="console">
[name@server]$ sudo zpool create -f data /dev/vdb /dev/vdc
</source>
This will create a new mount point at <code>/data</code> backed by the volumes attached at <code>/dev/vdb</code> and <code>/dev/vdc</code>. The filesystem will have a size slightly smaller than the combined sizes of all attached volumes. As data is written to the <code>/data</code> mount point it will be dynamically stripped across all drives. This is good for permformance and allows you to make use of all your storage, however it doesn't provide any additional data replication (see [https://www.freebsd.org/doc/handbook/zfs-zpool.html here] for information about creating mirrored zpools).

ZFS can compress data as it is written to the file system and uncompress it when it is read. To turn on and choose a compression algorithim for a zpool use the following command.
<source lang="console">
[name@server]$ sudo zfs set compression=lz4 data
</source>
This will use the [https://en.wikipedia.org/wiki/LZ4_(compression_algorithm) lz4] compression algorithm on the zpool <code>data</code>. If your data is largely binary you might not see large reduction in storage use, however, if your data is something more compressible, such as ascii data, you may see a larger reduction in storage use. Using compression can also improve file IO performance because less data needs to read and written. However this can depend on the particular compression algorithm chosen and some particularly computationally intensive algrothims may actually reduce file IO performance. The lz4 algorithm was choosen because it is a resonable compromise between speed and amount of compression achieved, other compression algorithms may provide better compression or speed but likely not both.

To see a list of peroperties for your pool use the below command.
<source lang="console">
[name@server]$ sudo zfs get all data
NAME  PROPERTY              VALUE                  SOURCE
data  type                  filesystem             -
data  creation              Fri Mar  1 17:57 2019  -
data  used                  82.5K                  -
data  available             19.3G                  -
data  referenced            24K                    -
data  compressratio         1.00x                  -
data  mounted               yes                    -
data  quota                 none                   default
...
</source>

zpools can be further subdived into datasets. A dataset allows you to operate on smaller portions of your zpool independently. For example setting a different compression algorithims for the dataset. To create a dataset within the <code>data</code> zpool do the following.
<source lang="console">
[name@server]$ sudo zfs create data/www
</source>

==Growing a zpool==
Growing a zpool is a relatively simple task when compared to other file systems and logical volume mangers. It is a two step process 1) add a new volume to your VM and 2) add the new device to your zpool that's it. Below is the command to add a new device to the zpool <code>data</code>.
<source lang="console">
[name@server]$ sudo zpool add data /dev/vde
</source>
The zpool will now have access to the added storage contributed by the newly added device. This process usually takes less than a minute even for very large several TB sized zpools and volumes.
Check pool status
<source lang="console">
[name@server]$ sudo zpool status data
</source>

==Destroying a zpool==
<source lang="console">
[name@server]$ sudo zpool destroy data
</source>

=Notes=
*While in theory it should be possible to use ZFS with resizing volumes in OpenStack in practices this has not been straight forward and is better to be avoided if possible.
*While there is no hard limit to how many volumes you can attach to your VM it is best to keep the number of volumes attached to a reasonable number. 19 attached volumes has been tested and shown to work well with the Queens version of OpenStack.
*Having a pool of two or more volumes may provide improved IO performance.

=See also=
* [https://www.freebsd.org/doc/handbook/zfs.html https://www.freebsd.org/doc/handbook/zfs.html]

[[Category:Cloud]]