<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>TensorFlow - Alliance Doc</title>
<script>(function(){var className="client-js";var cookie=document.cookie.match(/(?:^|; )ccwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\w+$|[^\w-]+/g,'')+'-clientpref-\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":[",\t."," \t,"],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","janvier","février","mars","avril","mai","juin","juillet","août","septembre","octobre","novembre","décembre"],"wgRequestId":"aDpFAY34nW-BQYizeTZIZQAAA04","wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"TensorFlow/fr","wgTitle":"TensorFlow/fr","wgCurRevisionId":157643,"wgRevisionId":157643,"wgArticleId":3617,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Software",
"AI and Machine Learning"],"wgPageViewLanguage":"fr","wgPageContentLanguage":"fr","wgPageContentModel":"wikitext","wgRelevantPageName":"TensorFlow/fr","wgRelevantArticleId":3617,"wgIsProbablyEditable":false,"wgRelevantPageIsProbablyEditable":false,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgULSAcceptLanguageList":[],"wgMFDisplayWikibaseDescriptions":{"search":false,"watchlist":false,"tagline":false},"wgCiteReferencePreviewsActive":true,"wgTranslatePageTranslation":"translation","wgULSPosition":"personal","wgULSisCompactLinksEnabled":true,"wgVector2022LanguageInHeader":false,"wgULSisLanguageSelectorEmpty":false};RLSTATE={"site.styles":"ready","user.styles":"ready","user":"ready","user.options":"loading","ext.translate.tag.languages":"ready","ext.pygments":"ready","skins.vector.styles.legacy":"ready","ext.translate":"ready","codex-search-styles":"ready","ext.uls.pt":"ready"};RLPAGEMODULES=["ext.tabs","ext.pygments.view","site","mediawiki.page.ready","mediawiki.toc",
"skins.vector.legacy.js","ext.languageSelector","ext.translate.pagetranslation.uls","ext.uls.compactlinks","ext.uls.geoclient","ext.uls.interface","ext.moderation.notify","ext.moderation.notify.desktop"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return["user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
}];});});</script>
<link rel="stylesheet" href="/mediawiki/load.php?lang=en&amp;modules=codex-search-styles%7Cext.pygments%2Ctranslate%7Cext.translate.tag.languages%7Cext.uls.pt%7Cskins.vector.styles.legacy&amp;only=styles&amp;skin=vector">
<script async="" src="/mediawiki/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="/mediawiki/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector">
<meta name="generator" content="MediaWiki 1.43.0">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta name="viewport" content="width=1120">
<link rel="icon" href="/mediawiki/resources/assets/Alliance_favicon.png">
<link rel="search" type="application/opensearchdescription+xml" href="/mediawiki/rest.php/v1/search" title="Alliance Doc (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://docs.alliancecan.ca/mediawiki/api.php?action=rsd">
<link rel="alternate" type="application/atom+xml" title="Alliance Doc Atom feed" href="/mediawiki/index.php?title=Special:RecentChanges&amp;feed=atom">
<style type="text/css" id="tabs-dynamic-styles">/*<![CDATA[*/
/* Dynamically generated tabs styles */
.tabs-input-1:checked ~ .tabs-container .tabs-content-1,
.tabs-input-2:checked ~ .tabs-container .tabs-content-2,
.tabs-input-0:checked ~ .tabs-container .tabs-content-1 {display:inline-block;}
.tabs-input-1:checked ~ .tabs-container .tabs-inline.tabs-content-1,
.tabs-input-2:checked ~ .tabs-container .tabs-inline.tabs-content-2,
.tabs-input-0:checked ~ .tabs-container .tabs-inline.tabs-content-1 {display:inline;}
.tabs-input-1:checked ~ .tabs-container .tabs-block.tabs-content-1,
.tabs-input-2:checked ~ .tabs-container .tabs-block.tabs-content-2,
.tabs-input-0:checked ~ .tabs-container .tabs-block.tabs-content-1 {display:block;}
/* The same styles, but with .checked instead of :checked, for browsers that rely on the JavaScript fallback */
.tabs-input-1.checked ~ .tabs-container .tabs-content-1,
.tabs-input-2.checked ~ .tabs-container .tabs-content-2,
.tabs-input-0.checked ~ .tabs-container .tabs-content-1 {display:inline-block;}
.tabs-input-1.checked ~ .tabs-container .tabs-inline.tabs-content-1,
.tabs-input-2.checked ~ .tabs-container .tabs-inline.tabs-content-2,
.tabs-input-0.checked ~ .tabs-container .tabs-inline.tabs-content-1 {display:inline;}
.tabs-input-1.checked ~ .tabs-container .tabs-block.tabs-content-1,
.tabs-input-2.checked ~ .tabs-container .tabs-block.tabs-content-2,
.tabs-input-0.checked ~ .tabs-container .tabs-block.tabs-content-1 {display:block;}
.tabs-dropdown .tabs-content,.tabs-dropdown .tabs-container,.tabs-dropdown li,.tabs-dropdown ul,.tabs-dropdown ol {background-color: white /* Malicious data in tabs-dropdown-bgcolor */}
/*]]>*/</style>
</head>
<body class="skin-vector-legacy mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-TensorFlow_fr rootpage-TensorFlow_fr skin-vector action-view"><div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice"></div>
	<div class="mw-indicators">
	<div id="mw-indicator-languageselector" class="mw-indicator"><span id="languageselector-box-1" class="languageselector " style=""><form name="languageselector-form-1" id="languageselector-form-1" method="get" action="/mediawiki/index.php" style="display:inline;"><input type="hidden" value="TensorFlow/fr" name="title"><select name="setlang" id="languageselector-select-1" style=""><option value="aae">Arbërisht</option><option value="ab">аԥсшәа</option><option value="abs">bahasa ambon</option><option value="ace">Acèh</option><option value="acf">Kwéyòl Sent Lisi</option><option value="acm">عراقي</option><option value="ady">адыгабзэ</option><option value="ady-cyrl">адыгабзэ</option><option value="aeb">تونسي / Tûnsî</option><option value="aeb-arab">تونسي</option><option value="aeb-latn">Tûnsî</option><option value="af">Afrikaans</option><option value="aln">Gegë</option><option value="alt">алтай тил</option><option value="am">አማርኛ</option><option value="ami">Pangcah</option><option value="an">aragonés</option><option value="ang">Ænglisc</option><option value="ann">Obolo</option><option value="anp">अंगिका</option><option value="apc">شامي</option><option value="ar">العربية</option><option value="arc">ܐܪܡܝܐ</option><option value="arn">mapudungun</option><option value="arq">جازايرية</option><option value="ary">الدارجة</option><option value="arz">مصرى</option><option value="as">অসমীয়া</option><option value="ase">American sign language</option><option value="ast">asturianu</option><option value="atj">Atikamekw</option><option value="av">авар</option><option value="avk">Kotava</option><option value="awa">अवधी</option><option value="ay">Aymar aru</option><option value="az">azərbaycanca</option><option value="azb">تۆرکجه</option><option value="ba">башҡортса</option><option value="ban">Basa Bali</option><option value="ban-bali">ᬩᬲᬩᬮᬶ</option><option value="bar">Boarisch</option><option value="bbc">Batak Toba</option><option value="bbc-latn">Batak Toba</option><option value="bcc">جهلسری بلوچی</option><option value="bci">wawle</option><option value="bcl">Bikol Central</option><option value="bdr">Bajau Sama</option><option value="be">беларуская</option><option value="be-tarask">беларуская (тарашкевіца)</option><option value="bew">Betawi</option><option value="bg">български</option><option value="bgc">हरियाणवी</option><option value="bgn">روچ کپتین بلوچی</option><option value="bh">भोजपुरी</option><option value="bho">भोजपुरी</option><option value="bi">Bislama</option><option value="bjn">Banjar</option><option value="blk">ပအိုဝ်ႏဘာႏသာႏ</option><option value="bm">bamanankan</option><option value="bn">বাংলা</option><option value="bo">བོད་ཡིག</option><option value="bpy">বিষ্ণুপ্রিয়া মণিপুরী</option><option value="bqi">بختیاری</option><option value="br">brezhoneg</option><option value="brh">Bráhuí</option><option value="bs">bosanski</option><option value="btm">Batak Mandailing</option><option value="bto">Iriga Bicolano</option><option value="bug">Basa Ugi</option><option value="bxr">буряад</option><option value="ca">català</option><option value="cbk-zam">Chavacano de Zamboanga</option><option value="ccp">𑄌𑄋𑄴𑄟𑄳𑄦</option><option value="cdo">閩東語 / Mìng-dĕ̤ng-ngṳ̄</option><option value="ce">нохчийн</option><option value="ceb">Cebuano</option><option value="ch">Chamoru</option><option value="chn">chinuk wawa</option><option value="chr">ᏣᎳᎩ</option><option value="chy">Tsetsêhestâhese</option><option value="ckb">کوردی</option><option value="co">corsu</option><option value="cps">Capiceño</option><option value="cpx">莆仙語 / Pó-sing-gṳ̂</option><option value="cpx-hans">莆仙语（简体）</option><option value="cpx-hant">莆仙語（繁體）</option><option value="cr">Nēhiyawēwin / ᓀᐦᐃᔭᐍᐏᐣ</option><option value="crh">qırımtatarca</option><option value="crh-cyrl">къырымтатарджа (Кирилл)</option><option value="crh-latn">qırımtatarca (Latin)</option><option value="crh-ro">tatarşa</option><option value="cs">čeština</option><option value="csb">kaszëbsczi</option><option value="cu">словѣньскъ / ⰔⰎⰑⰂⰡⰐⰠⰔⰍⰟ</option><option value="cv">чӑвашла</option><option value="cy">Cymraeg</option><option value="da">dansk</option><option value="dag">dagbanli</option><option value="de">Deutsch</option><option value="de-at">Österreichisches Deutsch</option><option value="de-ch">Schweizer Hochdeutsch</option><option value="de-formal">Deutsch (Sie-Form)</option><option value="dga">Dagaare</option><option value="din">Thuɔŋjäŋ</option><option value="diq">Zazaki</option><option value="dsb">dolnoserbski</option><option value="dtp">Kadazandusun</option><option value="dty">डोटेली</option><option value="dua">Duálá</option><option value="dv">ދިވެހިބަސް</option><option value="dz">ཇོང་ཁ</option><option value="ee">eʋegbe</option><option value="efi">Efịk</option><option value="egl">emiliàn e rumagnòl</option><option value="el">Ελληνικά</option><option value="eml">emiliàn e rumagnòl</option><option value="en" selected="">English</option><option value="en-ca">Canadian English</option><option value="en-gb">British English</option><option value="eo">Esperanto</option><option value="es">español</option><option value="es-formal">español (formal)</option><option value="et">eesti</option><option value="eu">euskara</option><option value="ext">estremeñu</option><option value="fa">فارسی</option><option value="fat">mfantse</option><option value="ff">Fulfulde</option><option value="fi">suomi</option><option value="fit">meänkieli</option><option value="fj">Na Vosa Vakaviti</option><option value="fo">føroyskt</option><option value="fon">fɔ̀ngbè</option><option value="fr">français</option><option value="frc">français cadien</option><option value="frp">arpetan</option><option value="frr">Nordfriisk</option><option value="fur">furlan</option><option value="fy">Frysk</option><option value="ga">Gaeilge</option><option value="gaa">Ga</option><option value="gag">Gagauz</option><option value="gan">贛語</option><option value="gan-hans">赣语（简体）</option><option value="gan-hant">贛語（繁體）</option><option value="gcf">kréyòl Gwadloup</option><option value="gcr">kriyòl gwiyannen</option><option value="gd">Gàidhlig</option><option value="gl">galego</option><option value="gld">на̄ни</option><option value="glk">گیلکی</option><option value="gn">Avañe'ẽ</option><option value="gom">गोंयची कोंकणी / Gõychi Konknni</option><option value="gom-deva">गोंयची कोंकणी</option><option value="gom-latn">Gõychi Konknni</option><option value="gor">Bahasa Hulontalo</option><option value="got">𐌲𐌿𐍄𐌹𐍃𐌺</option><option value="gpe">Ghanaian Pidgin</option><option value="grc">Ἀρχαία ἑλληνικὴ</option><option value="gsw">Alemannisch</option><option value="gu">ગુજરાતી</option><option value="guc">wayuunaiki</option><option value="gur">farefare</option><option value="guw">gungbe</option><option value="gv">Gaelg</option><option value="ha">Hausa</option><option value="hak">客家語 / Hak-kâ-ngî</option><option value="haw">Hawaiʻi</option><option value="he">עברית</option><option value="hi">हिन्दी</option><option value="hif">Fiji Hindi</option><option value="hif-latn">Fiji Hindi</option><option value="hil">Ilonggo</option><option value="hno">ہندکو</option><option value="hr">hrvatski</option><option value="hrx">Hunsrik</option><option value="hsb">hornjoserbsce</option><option value="hsn">湘語</option><option value="ht">Kreyòl ayisyen</option><option value="hu">magyar</option><option value="hu-formal">magyar (formal)</option><option value="hy">հայերեն</option><option value="hyw">Արեւմտահայերէն</option><option value="ia">interlingua</option><option value="iba">Jaku Iban</option><option value="ibb">ibibio</option><option value="id">Bahasa Indonesia</option><option value="ie">Interlingue</option><option value="ig">Igbo</option><option value="igl">Igala</option><option value="ii">ꆇꉙ</option><option value="ik">Iñupiatun</option><option value="ike-cans">ᐃᓄᒃᑎᑐᑦ</option><option value="ike-latn">inuktitut</option><option value="ilo">Ilokano</option><option value="inh">гӀалгӀай</option><option value="io">Ido</option><option value="is">íslenska</option><option value="isv-cyrl">меджусловјанскы</option><option value="isv-latn">medžuslovjansky</option><option value="it">italiano</option><option value="iu">ᐃᓄᒃᑎᑐᑦ / inuktitut</option><option value="ja">日本語</option><option value="jam">Patois</option><option value="jbo">la .lojban.</option><option value="jut">jysk</option><option value="jv">Jawa</option><option value="ka">ქართული</option><option value="kaa">Qaraqalpaqsha</option><option value="kab">Taqbaylit</option><option value="kai">Karai-karai</option><option value="kbd">адыгэбзэ</option><option value="kbd-cyrl">адыгэбзэ</option><option value="kbp">Kabɩyɛ</option><option value="kcg">Tyap</option><option value="kea">kabuverdianu</option><option value="kg">Kongo</option><option value="kge">Kumoring</option><option value="khw">کھوار</option><option value="ki">Gĩkũyũ</option><option value="kiu">Kırmancki</option><option value="kjh">хакас</option><option value="kjp">ဖၠုံလိက်</option><option value="kk">қазақша</option><option value="kk-arab">قازاقشا (تٴوتە)</option><option value="kk-cn">قازاقشا (جۇنگو)</option><option value="kk-cyrl">қазақша (кирил)</option><option value="kk-kz">қазақша (Қазақстан)</option><option value="kk-latn">qazaqşa (latın)</option><option value="kk-tr">qazaqşa (Türkïya)</option><option value="kl">kalaallisut</option><option value="km">ភាសាខ្មែរ</option><option value="kn">ಕನ್ನಡ</option><option value="knc">Yerwa Kanuri</option><option value="ko">한국어</option><option value="ko-kp">조선말</option><option value="koi">перем коми</option><option value="kr">kanuri</option><option value="krc">къарачай-малкъар</option><option value="kri">Krio</option><option value="krj">Kinaray-a</option><option value="krl">karjal</option><option value="ks">कॉशुर / کٲشُر</option><option value="ks-arab">کٲشُر</option><option value="ks-deva">कॉशुर</option><option value="ksh">Ripoarisch</option><option value="ksw">စှီၤ</option><option value="ku">kurdî</option><option value="ku-arab">کوردی (عەرەبی)</option><option value="ku-latn">kurdî (latînî)</option><option value="kum">къумукъ</option><option value="kus">Kʋsaal</option><option value="kv">коми</option><option value="kw">kernowek</option><option value="ky">кыргызча</option><option value="la">Latina</option><option value="lad">Ladino</option><option value="lb">Lëtzebuergesch</option><option value="lbe">лакку</option><option value="lez">лезги</option><option value="lfn">Lingua Franca Nova</option><option value="lg">Luganda</option><option value="li">Limburgs</option><option value="lij">Ligure</option><option value="liv">Līvõ kēļ</option><option value="lki">لەکی</option><option value="lld">Ladin</option><option value="lmo">lombard</option><option value="ln">lingála</option><option value="lo">ລາວ</option><option value="loz">Silozi</option><option value="lrc">لۊری شومالی</option><option value="lt">lietuvių</option><option value="ltg">latgaļu</option><option value="lua">ciluba</option><option value="lus">Mizo ţawng</option><option value="luz">لئری دوٙمینی</option><option value="lv">latviešu</option><option value="lzh">文言</option><option value="lzz">Lazuri</option><option value="mad">Madhurâ</option><option value="mag">मगही</option><option value="mai">मैथिली</option><option value="map-bms">Basa Banyumasan</option><option value="mdf">мокшень</option><option value="mg">Malagasy</option><option value="mhr">олык марий</option><option value="mi">Māori</option><option value="min">Minangkabau</option><option value="mk">македонски</option><option value="ml">മലയാളം</option><option value="mn">монгол</option><option value="mnc">manju gisun</option><option value="mnc-latn">manju gisun</option><option value="mnc-mong">ᠮᠠᠨᠵᡠ ᡤᡳᠰᡠᠨ</option><option value="mni">ꯃꯤꯇꯩ ꯂꯣꯟ</option><option value="mnw">ဘာသာမန်</option><option value="mo">молдовеняскэ</option><option value="mos">moore</option><option value="mr">मराठी</option><option value="mrh">Mara</option><option value="mrj">кырык мары</option><option value="ms">Bahasa Melayu</option><option value="ms-arab">بهاس ملايو</option><option value="mt">Malti</option><option value="mui">Baso Palembang</option><option value="mwl">Mirandés</option><option value="my">မြန်မာဘာသာ</option><option value="myv">эрзянь</option><option value="mzn">مازِرونی</option><option value="na">Dorerin Naoero</option><option value="nah">Nāhuatl</option><option value="nan">閩南語 / Bân-lâm-gú</option><option value="nan-hant">閩南語（傳統漢字）</option><option value="nan-latn-pehoeji">Bân-lâm-gú (Pe̍h-ōe-jī)</option><option value="nan-latn-tailo">Bân-lâm-gú (Tâi-lô)</option><option value="nap">Napulitano</option><option value="nb">norsk bokmål</option><option value="nds">Plattdüütsch</option><option value="nds-nl">Nedersaksies</option><option value="ne">नेपाली</option><option value="new">नेपाल भाषा</option><option value="nia">Li Niha</option><option value="nit">కొలామి</option><option value="niu">Niuē</option><option value="nl">Nederlands</option><option value="nl-informal">Nederlands (informeel)</option><option value="nmz">nawdm</option><option value="nn">norsk nynorsk</option><option value="nod">ᨣᩤᩴᨾᩮᩬᩥᨦ</option><option value="nog">ногайша</option><option value="nov">Novial</option><option value="nqo">ߒߞߏ</option><option value="nr">isiNdebele seSewula</option><option value="nrm">Nouormand</option><option value="nso">Sesotho sa Leboa</option><option value="nup">Nupe</option><option value="nv">Diné bizaad</option><option value="ny">Chi-Chewa</option><option value="nyn">runyankore</option><option value="nyo">Orunyoro</option><option value="nys">Nyunga</option><option value="oc">occitan</option><option value="ojb">Ojibwemowin</option><option value="olo">livvinkarjala</option><option value="om">Oromoo</option><option value="or">ଓଡ଼ିଆ</option><option value="os">ирон</option><option value="pa">ਪੰਜਾਬੀ</option><option value="pag">Pangasinan</option><option value="pam">Kapampangan</option><option value="pap">Papiamentu</option><option value="pcd">Picard</option><option value="pcm">Naijá</option><option value="pdc">Deitsch</option><option value="pdt">Plautdietsch</option><option value="pfl">Pälzisch</option><option value="pi">पालि</option><option value="pih">Norfuk / Pitkern</option><option value="pl">polski</option><option value="pms">Piemontèis</option><option value="pnb">پنجابی</option><option value="pnt">Ποντιακά</option><option value="prg">prūsiskan</option><option value="ps">پښتو</option><option value="pt">português</option><option value="pt-br">português do Brasil</option><option value="pwn">pinayuanan</option><option value="qqq">Message documentation</option><option value="qu">Runa Simi</option><option value="qug">Runa shimi</option><option value="rgn">Rumagnôl</option><option value="rif">Tarifit</option><option value="rki">ရခိုင်</option><option value="rm">rumantsch</option><option value="rmc">romaňi čhib</option><option value="rmy">romani čhib</option><option value="rn">ikirundi</option><option value="ro">română</option><option value="roa-tara">tarandíne</option><option value="rsk">руски</option><option value="ru">русский</option><option value="rue">русиньскый</option><option value="rup">armãneashti</option><option value="ruq">Vlăheşte</option><option value="ruq-cyrl">Влахесте</option><option value="ruq-latn">Vlăheşte</option><option value="rut">мыхаӀбишды</option><option value="rw">Ikinyarwanda</option><option value="ryu">うちなーぐち</option><option value="sa">संस्कृतम्</option><option value="sah">саха тыла</option><option value="sat">ᱥᱟᱱᱛᱟᱲᱤ</option><option value="sc">sardu</option><option value="scn">sicilianu</option><option value="sco">Scots</option><option value="sd">سنڌي</option><option value="sdc">Sassaresu</option><option value="sdh">کوردی خوارگ</option><option value="se">davvisámegiella</option><option value="se-fi">davvisámegiella (Suoma bealde)</option><option value="se-no">davvisámegiella (Norgga bealde)</option><option value="se-se">davvisámegiella (Ruoŧa bealde)</option><option value="sei">Cmique Itom</option><option value="ses">Koyraboro Senni</option><option value="sg">Sängö</option><option value="sgs">žemaitėška</option><option value="sh">srpskohrvatski / српскохрватски</option><option value="sh-cyrl">српскохрватски (ћирилица)</option><option value="sh-latn">srpskohrvatski (latinica)</option><option value="shi">Taclḥit</option><option value="shn">ၽႃႇသႃႇတႆး </option><option value="shy">tacawit</option><option value="shy-latn">tacawit</option><option value="si">සිංහල</option><option value="sjd">кӣллт са̄мь кӣлл</option><option value="sje">bidumsámegiella</option><option value="sk">slovenčina</option><option value="skr">سرائیکی</option><option value="skr-arab">سرائیکی</option><option value="sl">slovenščina</option><option value="sli">Schläsch</option><option value="sm">Gagana Samoa</option><option value="sma">åarjelsaemien</option><option value="smn">anarâškielâ</option><option value="sms">nuõrttsääʹmǩiõll</option><option value="sn">chiShona</option><option value="so">Soomaaliga</option><option value="sq">shqip</option><option value="sr">српски / srpski</option><option value="sr-ec">српски (ћирилица)</option><option value="sr-el">srpski (latinica)</option><option value="srn">Sranantongo</option><option value="sro">sardu campidanesu</option><option value="ss">SiSwati</option><option value="st">Sesotho</option><option value="stq">Seeltersk</option><option value="sty">себертатар</option><option value="su">Sunda</option><option value="sv">svenska</option><option value="sw">Kiswahili</option><option value="syl">ꠍꠤꠟꠐꠤ</option><option value="szl">ślůnski</option><option value="szy">Sakizaya</option><option value="ta">தமிழ்</option><option value="tay">Tayal</option><option value="tcy">ತುಳು</option><option value="tdd">ᥖᥭᥰ ᥖᥬᥲ ᥑᥨᥒᥰ</option><option value="te">తెలుగు</option><option value="tet">tetun</option><option value="tg">тоҷикӣ</option><option value="tg-cyrl">тоҷикӣ</option><option value="tg-latn">tojikī</option><option value="th">ไทย</option><option value="ti">ትግርኛ</option><option value="tig">ትግሬ</option><option value="tk">Türkmençe</option><option value="tl">Tagalog</option><option value="tly">tolışi</option><option value="tn">Setswana</option><option value="to">lea faka-Tonga</option><option value="tok">toki pona</option><option value="tpi">Tok Pisin</option><option value="tr">Türkçe</option><option value="tru">Ṫuroyo</option><option value="trv">Seediq</option><option value="ts">Xitsonga</option><option value="tt">татарча / tatarça</option><option value="tt-cyrl">татарча</option><option value="tt-latn">tatarça</option><option value="ttj">Orutooro</option><option value="tum">chiTumbuka</option><option value="tw">Twi</option><option value="ty">reo tahiti</option><option value="tyv">тыва дыл</option><option value="tzm">ⵜⴰⵎⴰⵣⵉⵖⵜ</option><option value="udm">удмурт</option><option value="ug">ئۇيغۇرچە / Uyghurche</option><option value="ug-arab">ئۇيغۇرچە</option><option value="ug-latn">Uyghurche</option><option value="uk">українська</option><option value="ur">اردو</option><option value="uz">oʻzbekcha / ўзбекча</option><option value="ve">Tshivenda</option><option value="vec">vèneto</option><option value="vep">vepsän kel’</option><option value="vi">Tiếng Việt</option><option value="vls">West-Vlams</option><option value="vmf">Mainfränkisch</option><option value="vmw">emakhuwa</option><option value="vo">Volapük</option><option value="vot">Vaďďa</option><option value="vro">võro</option><option value="wa">walon</option><option value="wal">wolaytta</option><option value="war">Winaray</option><option value="wls">Fakaʻuvea</option><option value="wo">Wolof</option><option value="wuu">吴语</option><option value="wuu-hans">吴语（简体）</option><option value="wuu-hant">吳語（正體）</option><option value="xal">хальмг</option><option value="xh">isiXhosa</option><option value="xmf">მარგალური</option><option value="xsy">saisiyat</option><option value="yi">ייִדיש</option><option value="yo">Yorùbá</option><option value="yrl">Nhẽẽgatú</option><option value="yue">粵語</option><option value="yue-hans">粵语（简体）</option><option value="yue-hant">粵語（繁體）</option><option value="za">Vahcuengh</option><option value="zea">Zeêuws</option><option value="zgh">ⵜⴰⵎⴰⵣⵉⵖⵜ ⵜⴰⵏⴰⵡⴰⵢⵜ</option><option value="zh">中文</option><option value="zh-cn">中文（中国大陆）</option><option value="zh-hans">中文（简体）</option><option value="zh-hant">中文（繁體）</option><option value="zh-hk">中文（香港）</option><option value="zh-mo">中文（澳門）</option><option value="zh-my">中文（马来西亚）</option><option value="zh-sg">中文（新加坡）</option><option value="zh-tw">中文（臺灣）</option><option value="zu">isiZulu</option></select><input id="languageselector-commit-1" style="" type="submit" value="set"></form></span></div>
	</div>
	<h1 id="firstHeading" class="firstHeading mw-first-heading">TensorFlow</h1>
	<div id="bodyContent" class="vector-body">
		<div id="siteSub" class="noprint">From Alliance Doc</div>
		<div id="contentSub"><div id="mw-content-subtitle"></div></div>
		<div id="contentSub2"></div>
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#searchInput">Jump to search</a>
		<div id="mw-content-text" class="mw-body-content"><div class="mw-pt-translate-header noprint" dir="ltr" lang="en">This page is a <span class="plainlinks"><a rel="nofollow" class="external text" href="https://docs.alliancecan.ca/mediawiki/index.php?title=Special:Translate&amp;group=page-TensorFlow&amp;action=page&amp;filter=&amp;language=fr">translated version</a></span> of the page <a href="/wiki/TensorFlow" title="TensorFlow">TensorFlow</a> and the translation is 100% complete.</div><div class="mw-content-ltr mw-parser-output" lang="fr" dir="ltr"><div class="mw-pt-languages noprint navigation-not-searchable" lang="en" dir="ltr"><div class="mw-pt-languages-label">Other languages:</div><ul class="mw-pt-languages-list"><li><a href="/wiki/TensorFlow" class="mw-pt-languages-ui mw-pt-progress mw-pt-progress--complete" title="TensorFlow (100% translated)" lang="en" dir="ltr">English</a></li>
<li><span class="mw-pt-languages-selected mw-pt-progress mw-pt-progress--complete" lang="fr" dir="ltr">français</span></li></ul></div> 
<p><a rel="nofollow" class="external text" href="https://www.tensorflow.org/">TensorFlow</a> est une bibliothèque logicielle <i>open source</i> d'apprentissage machine.
</p><p>Si vous voulez porter un programme TensorFlow sur une de nos grappes, nous vous recommandons de prendre connaissance du <a href="/wiki/Tutoriel_Apprentissage_machine" title="Tutoriel Apprentissage machine">tutoriel sur l'apprentissage machine</a>.
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Installation"><span class="tocnumber">1</span> <span class="toctext">Installation</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Le_paquet_R"><span class="tocnumber">1.1</span> <span class="toctext">Le paquet R</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-3"><a href="#Soumettre_une_tâche_TensorFlow_avec_un_GPU"><span class="tocnumber">2</span> <span class="toctext">Soumettre une tâche TensorFlow avec un GPU</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Suivi"><span class="tocnumber">3</span> <span class="toctext">Suivi</span></a>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#TensorBoard"><span class="tocnumber">3.1</span> <span class="toctext">TensorBoard</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6"><a href="#Utiliser_plusieurs_GPU"><span class="tocnumber">4</span> <span class="toctext">Utiliser plusieurs GPU</span></a>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#TensorFlow_1.x"><span class="tocnumber">4.1</span> <span class="toctext">TensorFlow 1.x</span></a>
<ul>
<li class="toclevel-3 tocsection-8"><a href="#Parameter_Server"><span class="tocnumber">4.1.1</span> <span class="toctext">Parameter Server</span></a></li>
<li class="toclevel-3 tocsection-9"><a href="#Replicated"><span class="tocnumber">4.1.2</span> <span class="toctext">Replicated</span></a></li>
<li class="toclevel-3 tocsection-10"><a href="#Étalonnage_(benchmarks)"><span class="tocnumber">4.1.3</span> <span class="toctext">Étalonnage (<i>benchmarks</i>)</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-11"><a href="#TensorFlow_2.x"><span class="tocnumber">4.2</span> <span class="toctext">TensorFlow 2.x</span></a>
<ul>
<li class="toclevel-3 tocsection-12"><a href="#Stratégie_miroir"><span class="tocnumber">4.2.1</span> <span class="toctext">Stratégie miroir</span></a>
<ul>
<li class="toclevel-4 tocsection-13"><a href="#Nœud_unique"><span class="tocnumber">4.2.1.1</span> <span class="toctext">Nœud unique</span></a></li>
<li class="toclevel-4 tocsection-14"><a href="#Nœuds_multiples"><span class="tocnumber">4.2.1.2</span> <span class="toctext">Nœuds multiples</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-15"><a href="#Horovod"><span class="tocnumber">4.2.2</span> <span class="toctext">Horovod</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-16"><a href="#Créer_des_points_de_contrôle"><span class="tocnumber">5</span> <span class="toctext">Créer des points de contrôle</span></a>
<ul>
<li class="toclevel-2 tocsection-17"><a href="#Avec_Keras"><span class="tocnumber">5.1</span> <span class="toctext">Avec Keras</span></a></li>
<li class="toclevel-2 tocsection-18"><a href="#Avec_une_boucle_d&#39;entraînement_personnalisée"><span class="tocnumber">5.2</span> <span class="toctext">Avec une boucle d'entraînement personnalisée</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-19"><a href="#Opérateurs_personnalisés"><span class="tocnumber">6</span> <span class="toctext">Opérateurs personnalisés</span></a>
<ul>
<li class="toclevel-2 tocsection-20"><a href="#TensorFlow_&lt;=_1.4.x"><span class="tocnumber">6.1</span> <span class="toctext">TensorFlow &lt;= 1.4.x</span></a></li>
<li class="toclevel-2 tocsection-21"><a href="#TensorFlow_&gt;_1.4.x"><span class="tocnumber">6.2</span> <span class="toctext">TensorFlow &gt; 1.4.x</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-22"><a href="#Dépannage"><span class="tocnumber">7</span> <span class="toctext">Dépannage</span></a>
<ul>
<li class="toclevel-2 tocsection-23"><a href="#scikit-image"><span class="tocnumber">7.1</span> <span class="toctext">scikit-image</span></a></li>
<li class="toclevel-2 tocsection-24"><a href="#libcupti.so"><span class="tocnumber">7.2</span> <span class="toctext">libcupti.so</span></a></li>
<li class="toclevel-2 tocsection-25"><a href="#libiomp5.so_invalid_ELF_header"><span class="tocnumber">7.3</span> <span class="toctext">libiomp5.so invalid ELF header</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-26"><a href="#Contrôle_du_nombre_de_CPU_et_de_fils"><span class="tocnumber">8</span> <span class="toctext">Contrôle du nombre de CPU et de fils</span></a>
<ul>
<li class="toclevel-2 tocsection-27"><a href="#TensorFlow_1.x_2"><span class="tocnumber">8.1</span> <span class="toctext">TensorFlow 1.x</span></a></li>
<li class="toclevel-2 tocsection-28"><a href="#TensorFlow_2.x_2"><span class="tocnumber">8.2</span> <span class="toctext">TensorFlow 2.x</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-29"><a href="#Problèmes_connus"><span class="tocnumber">9</span> <span class="toctext">Problèmes connus</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Installation">Installation</span></h2>
<p>Les directives suivantes servent à installer TensorFlow dans votre répertoire <i>home</i> à l'aide des (<a rel="nofollow" class="external text" href="http://pythonwheels.com/"><i>wheels</i> Python </a>) qui se trouvent dans <code>/cvmfs/soft.computecanada.ca/custom/python/wheelhouse/</code>. 
<br />
Le wheel TensorFlow sera installé dans un <a href="/wiki/Python/fr#Créer_et_utiliser_un_environnement_virtuel" title="Python/fr">environnement virtuel Python</a> avec la commande <code>pip</code>.
</p>
<form id="tabs-inputform" class="tabs tabs-inputform" action="#"></form><div class="tabs tabs-tabbox"><input type="radio" form="tabs-inputform" id="tabs-input-1-0" name="tabs-1" class="tabs-input tabs-input-0" checked="" /><input type="radio" form="tabs-inputform" id="tabs-input-1-1" name="tabs-1" class="tabs-input tabs-input-1" /><label class="tabs-label" for="tabs-input-1-1" data-tabpos="1">TF 2.x</label><wbr /><input type="radio" form="tabs-inputform" id="tabs-input-1-2" name="tabs-1" class="tabs-input tabs-input-2" /><label class="tabs-label" for="tabs-input-1-2" data-tabpos="2">TF 1.x</label><wbr /><div class="tabs-container" style="">
<div class="tabs-content tabs-content-1">
<p>Chargez les modules requis par TensorFlow; dans certains cas, d'autres modules pourraient être requis (par exemple CUDA).
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>python/3
</pre></div></div>
<p><br />
Créez un nouvel environnement Python.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>virtualenv<span class="w"> </span>--no-download<span class="w"> </span>tensorflow
</pre></div></div>
<p><br />
Activez le nouvel environnement.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span><span class="nb">source</span><span class="w"> </span>tensorflow/bin/activate
</pre></div></div>
<p><br />
Installez TensorFlow dans votre nouvel environnement virtuel en utilisant la commande suivante.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp gp-VirtualEnv">(tensorflow)</span> <span class="gp">[name@server ~]$ </span>pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span><span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.8
</pre></div></div>
</div>
<div class="tabs-content tabs-content-2">
<p>Chargez les modules requis par TensorFlow. TF 1.x requiert StdEnv/2018.
</p><p><b>Remarque&#160;: TF 1.x n'est pas disponible sur Narval, puisque cette grappe n'offre pas StdEnv/2018.</b>
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>StdEnv/2018<span class="w"> </span>python/3
</pre></div></div>
<p><br />
Créez un nouvel environnement Python.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>virtualenv<span class="w"> </span>--no-download<span class="w"> </span>tensorflow
</pre></div></div>
<p><br />
Activez le nouvel environnement.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span><span class="nb">source</span><span class="w"> </span>tensorflow/bin/activate
</pre></div></div>
<p><br />
Installez TensorFlow dans votre nouvel environnement virtuel en utilisant une des commandes suivantes, dépendant de si vous avez besoin d'utiliser un GPU.
</p><p><b>N'installez pas</b> le paquet <code>tensorflow</code> sans le suffixe <code>_cpu</code> ou <code>_gpu</code> car il existe des problèmes de compatibilité avec d'autres bibliothèques.
</p>
<h3><span class="mw-headline" id="CPU_seulement">CPU seulement</span></h3>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp gp-VirtualEnv">(tensorflow)</span> <span class="gp">[name@server ~]$ </span>pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span><span class="nv">tensorflow_cpu</span><span class="o">==</span><span class="m">1</span>.15.0
</pre></div></div>
<p><br />
</p>
<h3><span class="mw-headline" id="GPU">GPU</span></h3>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp gp-VirtualEnv">(tensorflow)</span> <span class="gp">[name@server ~]$ </span>pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span><span class="nv">tensorflow_gpu</span><span class="o">==</span><span class="m">1</span>.15.0
</pre></div></div>
</div>
</div></div>
<p><br />
</p>
<h3><span class="mw-headline" id="Le_paquet_R">Le paquet R</span></h3>
<p>Pour utiliser TensorFlow en R, suivez les directives données ci-dessus pour créer un environnement virtuel et y installer TensorFlow. Suivez ensuite cette procédure ː
</p><p>Chargez les modules requis.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>gcc<span class="w"> </span>r
</pre></div></div>
<p>Activez votre environnement virtuel Python.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span><span class="nb">source</span><span class="w"> </span>tensorflow/bin/activate
</pre></div></div>
<p>Lancez R.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp gp-VirtualEnv">(tensorflow)</span><span class="gp">_[name@server ~]$ </span>R
</pre></div></div>
<p>En R, installez le paquet devtools, puis TensorFlow. 
</p>
<div class="mw-highlight mw-highlight-lang-r mw-content-ltr" dir="ltr"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&#39;devtools&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">repos</span><span class="o">=</span><span class="s">&#39;https://cloud.r-project.org&#39;</span><span class="p">)</span>
<span class="n">devtools</span><span class="o">::</span><span class="nf">install_github</span><span class="p">(</span><span class="s">&#39;rstudio/tensorflow&#39;</span><span class="p">)</span>
</pre></div>
<p>Vous pouvez maintenant procéder. N'appelez pas <code>install_tensorflow()</code> en R puisque TensorFlow est déjà installé dans votre environnement virtuel avec <code>pip</code>. Pour utiliser TensorFlow tel qu'installé dans votre environnement virtuel, entrez les commandes suivantes en R, après que l'environnement est activé.
</p>
<div class="mw-highlight mw-highlight-lang-r mw-content-ltr" dir="ltr"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="nf">use_virtualenv</span><span class="p">(</span><span class="nf">Sys.getenv</span><span class="p">(</span><span class="s">&#39;VIRTUAL_ENV&#39;</span><span class="p">))</span>
</pre></div>
<h2><span id="Soumettre_une_t.C3.A2che_TensorFlow_avec_un_GPU"></span><span class="mw-headline" id="Soumettre_une_tâche_TensorFlow_avec_un_GPU">Soumettre une tâche TensorFlow avec un GPU</span></h2>
<p>Soumettez une tâche TensorFlow ainsi 
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>sbatch<span class="w"> </span>tensorflow-test.sh
</pre></div></div>
<p>Le script contient
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-test.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%23SBATCH+--gres%3Dgpu%3A1++++++++%23+request+GPU+%22generic+resource%22%0A%23SBATCH+--cpus-per-task%3D6+++%23+maximum+CPU+cores+per+GPU+request%3A+6+on+Cedar%2C+16+on+Graham.%0A%23SBATCH+--mem%3D32000M++++++++%23+memory+per+node%0A%23SBATCH+--time%3D0-03%3A00++++++%23+time+%28DD-HH%3AMM%29%0A%23SBATCH+--output%3D%25N-%25j.out++%23+%25N+for+node+name%2C+%25j+for+jobID%0A%0Amodule+load+cuda+cudnn+%0Asource+tensorflow%2Fbin%2Factivate%0Apython+.%2Ftensorflow-test.py" />
<input type="hidden" name="filename" value="tensorflow-test.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --gres=gpu:1        # request GPU &quot;generic resource&quot;</span>
<span class="c1">#SBATCH --cpus-per-task=6   # maximum CPU cores per GPU request: 6 on Cedar, 16 on Graham.</span>
<span class="c1">#SBATCH --mem=32000M        # memory per node</span>
<span class="c1">#SBATCH --time=0-03:00      # time (DD-HH:MM)</span>
<span class="c1">#SBATCH --output=%N-%j.out  # %N for node name, %j for jobID</span>

module<span class="w"> </span>load<span class="w"> </span>cuda<span class="w"> </span>cudnn<span class="w"> </span>
<span class="nb">source</span><span class="w"> </span>tensorflow/bin/activate
python<span class="w"> </span>./tensorflow-test.py
</pre></div>
</div>
<p><br />
Le script Python se lit
</p>
<div class="tabs tabs-tabbox"><input type="radio" form="tabs-inputform" id="tabs-input-2-0" name="tabs-2" class="tabs-input tabs-input-0" checked="" /><input type="radio" form="tabs-inputform" id="tabs-input-2-1" name="tabs-2" class="tabs-input tabs-input-1" /><label class="tabs-label" for="tabs-input-2-1" data-tabpos="1">TF 2.x</label><wbr /><input type="radio" form="tabs-inputform" id="tabs-input-2-2" name="tabs-2" class="tabs-input tabs-input-2" /><label class="tabs-label" for="tabs-input-2-2" data-tabpos="2">TF 1.x</label><wbr /><div class="tabs-container" style="">
<div class="tabs-content tabs-content-1">
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-test.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Anode1+%3D+tf.constant%283.0%29%0Anode2+%3D+tf.constant%284.0%29%0Aprint%28node1%2C+node2%29%0Aprint%28node1+%2B+node2%29" />
<input type="hidden" name="filename" value="tensorflow-test.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">node1</span> <span class="o">+</span> <span class="n">node2</span><span class="p">)</span>
</pre></div>
</div>
<p><br />
</p>
</div>
<div class="tabs-content tabs-content-2">
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-test.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Anode1+%3D+tf.constant%283.0%29%0Anode2+%3D+tf.constant%284.0%29%0Aprint%28node1%2C+node2%29%0Asess+%3D+tf.Session%28%29%0Aprint%28sess.run%28node1+%2B+node2%29%29" />
<input type="hidden" name="filename" value="tensorflow-test.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">node1</span> <span class="o">+</span> <span class="n">node2</span><span class="p">))</span>
</pre></div>
</div>
<p><br />
</p>
</div>
</div></div>
<p>Une fois la tâche terminée, ce qui devrait nécessiter moins d'une minute, un fichier de sortie avec un nom semblable à <code>cdr116-122907.out</code> devrait être généré. Le contenu de ce fichier serait similaire à ce qui suit; il s'agit d'exemples de messages TensorFlow et il est possible que vous en ayez d'autres.
</p>
<div class="tabs tabs-tabbox"><input type="radio" form="tabs-inputform" id="tabs-input-3-0" name="tabs-3" class="tabs-input tabs-input-0" checked="" /><input type="radio" form="tabs-inputform" id="tabs-input-3-1" name="tabs-3" class="tabs-input tabs-input-1" /><label class="tabs-label" for="tabs-input-3-1" data-tabpos="1">TF 2.x</label><wbr /><input type="radio" form="tabs-inputform" id="tabs-input-3-2" name="tabs-3" class="tabs-input tabs-input-2" /><label class="tabs-label" for="tabs-input-3-2" data-tabpos="2">TF 1.x</label><wbr /><div class="tabs-container" style="">
<div class="tabs-content tabs-content-1">
<div class="code-file">
<div class="filename"><b>File&#160;:</b> cdr116-122907.out</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="2017-07-10+12%3A35%3A19.491097%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A961%5D+DMA%3A+0%0A2017-07-10+12%3A35%3A19.491156%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A971%5D+0%3A+++Y%0A2017-07-10+12%3A35%3A19.520737%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A1030%5D+Creating+TensorFlow+device+%28%2Fgpu%3A0%29+-%3E+%28device%3A+0%2C+name%3A+Tesla+P100-PCIE-12GB%2C+pci+bus+id%3A+0000%3A82%3A00.0%29%0Atf.Tensor%283.0%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29+tf.Tensor%284.0%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29%0Atf.Tensor%287.0%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29" />
<input type="hidden" name="filename" value="cdr116-122907.out" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-text mw-content-ltr" dir="ltr"><pre><span></span>2017-07-10 12:35:19.491097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
2017-07-10 12:35:19.491156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
2017-07-10 12:35:19.520737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:82:00.0)
tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(4.0, shape=(), dtype=float32)
tf.Tensor(7.0, shape=(), dtype=float32)
</pre></div>
</div>
<p><br />
</p>
</div>
<div class="tabs-content tabs-content-2">
<div class="code-file">
<div class="filename"><b>File&#160;:</b> cdr116-122907.out</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="2017-07-10+12%3A35%3A19.491097%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A961%5D+DMA%3A+0%0A2017-07-10+12%3A35%3A19.491156%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A971%5D+0%3A+++Y%0A2017-07-10+12%3A35%3A19.520737%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A1030%5D+Creating+TensorFlow+device+%28%2Fgpu%3A0%29+-%3E+%28device%3A+0%2C+name%3A+Tesla+P100-PCIE-12GB%2C+pci+bus+id%3A+0000%3A82%3A00.0%29%0ATensor%28%22Const%3A0%22%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29+Tensor%28%22Const_1%3A0%22%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29%0A7.0" />
<input type="hidden" name="filename" value="cdr116-122907.out" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-text mw-content-ltr" dir="ltr"><pre><span></span>2017-07-10 12:35:19.491097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
2017-07-10 12:35:19.491156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
2017-07-10 12:35:19.520737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:82:00.0)
Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32)
7.0
</pre></div>
</div>
<p><br />
</p>
</div>
</div></div>
<p><br />
TensorFlow fonctionne sur tous les types de nœuds GPU. Pour la recherche de grande envergure en apprentissage profond ou en apprentissage machine, il est fortement recommandé d'utiliser le type de nœuds <i>GPU large</i> de Cedar. Ces nœuds sont équipés de  4 x P100-PCIE-16Go avec <a rel="nofollow" class="external text" href="http://developer.download.nvidia.com/devzone/devcenter/cuda/docs/GPUDirect_Technology_Overview.pdf">GPUDirect P2P</a> entre chaque paire. Pour plus d'information, consultez <a href="/wiki/Using_GPUs_with_Slurm/fr" title="Using GPUs with Slurm/fr">cette page</a>.
</p>
<h2><span class="mw-headline" id="Suivi">Suivi</span></h2>
<p>Il est possible de se connecter à un nœud sur lequel une tâche est en cours pour y exécuter des processus. On peut ainsi faire le suivi des ressources utilisées par TensorFlow et visualiser le déroulement de l'entraînement. Pour des exemples, consultez <a href="/wiki/Running_jobs/fr#Surveillance_d&#39;une_tâche_en_cours" title="Running jobs/fr">Surveillance d'une tâche en cours</a>.
</p>
<h3><span class="mw-headline" id="TensorBoard">TensorBoard</span></h3>
<p>TensorFlow propose la suite d'outils de visualisation <a rel="nofollow" class="external text" href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard">TensorBoard</a> qui lit les événements TensorFlow et modélise les fichiers. Pour savoir comment créer ces fichiers, consultez <a rel="nofollow" class="external text" href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard#serializing_the_data">TensorBoard tutorial on summaries</a>.
</p><p>Sachez toutefois que TensorBoard exige trop de puissance de calcul pour être exécuté sur un nœud de connexion. Nous vous recommandons de l'exécuter dans la même tâche que le processus TensorFlow. Pour ce faire, lancez TensorBoard en arrière-plan en l'appelant avant le script Python, en y ajoutant le caractère (<code>&amp;</code>).
</p>
<pre># Your SBATCH arguments here

tensorboard --logdir=/tmp/your_log_dir --host 0.0.0.0 --load_fast false &amp;
python train.py  # example
</pre>
<p>Pour accéder TensorBoard avec un fureteur une fois que la tâche est en cours, il faut créer un lien entre votre ordinateur et le nœud sur lequel TensorFlow et TensorBoard sont exécutés. Pour ce faire, vous avez besoin du <i>hostname</i> du nœud de calcul sur lequel le serveur TensorFlow se trouve. Pour le trouver, faites afficher la liste de vos tâches avec la commande <code>sq</code> et repérez la tâche; le <i>hostname</i> est la valeur qui se trouve dans la colonne NODELIST.
</p><p>Pour créer la connexion, lancez la commande sur votre ordinateur local.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@my_computer ~]$ </span>ssh<span class="w"> </span>-N<span class="w"> </span>-f<span class="w"> </span>-L<span class="w"> </span>localhost:6006:computenode:6006<span class="w"> </span>userid@cluster.computecanada.ca
</pre></div></div>
<p><br />
Remplacez <code>computenode</code> par le <i>hostname</i> obtenu à l'étape précédente; <code>userid</code> par votre nom d'utilisateur de l'Alliance et; <code>cluster</code> par le <i>hostname</i> de la grappe, soit <code>beluga</code>, <code>cedar</code>, <code>graham</code>, etc. Si le port 6006 était déjà utilisé, tensorboard va en utiliser un autre (p. ex. 6007, 6008...).
</p><p>Une fois que la connexion est établie, allez à <a rel="nofollow" class="external text" href="http://localhost:6006">http://localhost:6006</a>.
</p>
<h2><span class="mw-headline" id="Utiliser_plusieurs_GPU">Utiliser plusieurs GPU</span></h2>
<h3><span class="mw-headline" id="TensorFlow_1.x">TensorFlow 1.x</span></h3>
<p>Il existe plusieurs méthodes de gestion des variables, les plus communes étant <i>Parameter Server</i> et <i>Replicated</i>. 
</p>
<ul><li>Nous allons utiliser <a rel="nofollow" class="external text" href="https://github.com/tensorflow/benchmarks">ce code</a> pour illustrer les diverses méthodes; vous pouvez l'adapter à vos besoins spécifiques.</li></ul>
<h4><span class="mw-headline" id="Parameter_Server">Parameter Server</span></h4>
<p>La copie maîtresse des variables est enregistrée sur un serveur de paramètres. En entraînement distribué, les serveurs de paramètres sont des processus distincts dans chacun des appareils. À chaque étape, chacune des tours obtient du serveur de paramètres une copie des variables et y retourne ses gradients.
</p><p>Les paramètres peuvent être enregistrés sur un CPU 
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=parameter_server --local_parameter_device=cpu
</pre>
<p>ou sur un GPU
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=parameter_server --local_parameter_device=gpu
</pre>
<h4><span class="mw-headline" id="Replicated">Replicated</span></h4>
<p>Chaque GPU possède sa propre copie des variables. Les gradients sont copiés sur toutes les tours par agrégation du contenu des appareils ou par un algorithme <i>all reduce</i> (dépendant de la valeur du paramètre all_reduce_spec).
</p><p>Avec la méthode <i>all reduce</i> par défaut ː 
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=replicated
</pre>
<p>Xring --- utilisez un <i>global ring reduction</i> pour tous les tenseurs&#160;:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=replicated --all_reduce_spec=xring
</pre>
<p>Pscpu --- utilisez CPU <i>at worker 0</i> pour réduire tous les tenseurs&#160;:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=replicated --all_reduce_spec=pscpu
</pre>
<p>NCCL --- utilisez NCCL pour réduire localement tous les tenseurs&#160;:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=replicated --all_reduce_spec=nccl
</pre>
<p>Les méthodes se comportent différemment selon les modèles; nous vous recommandons fortement de tester vos modèles avec toutes les méthodes sur les différents types de nœuds GPU.
</p>
<h4><span id=".C3.89talonnage_.28benchmarks.29"></span><span class="mw-headline" id="Étalonnage_(benchmarks)">Étalonnage (<i>benchmarks</i>)</span></h4>
<p>Les résultats ont été obtenus avec TensorFlow v1.5 (CUDA9 et cuDNN 7) sur Graham et Cedar avec un seul GPU et plusieurs GPU et des méthodes différentes de gestion des variables; voyez  <a rel="nofollow" class="external text" href="https://github.com/tensorflow/benchmarks">TensorFlow Benchmarks</a>. 
</p>
<ul><li>ResNet-50</li></ul>
<p>Lots de 32 par GPU et parallélisation des données (les résultats sont en images par seconde).
</p>
<table class="wikitable">

<tbody><tr>
<th>Type de nœud</th>
<th>1 GPU</th>
<th>Nombre de GPU</th>
<th>ps,cpu</th>
<th>ps, gpu</th>
<th>répliqué</th>
<th>répliqué, xring</th>
<th>répliqué, pscpu</th>
<th>répliqué, nccl
</th></tr>
<tr>
<td>Graham, <i>GPU base</i></td>
<td>171.23</td>
<td>2</td>
<td>93.31</td>
<td><b>324.04</b></td>
<td>318.33</td>
<td>316.01</td>
<td>109.82</td>
<td>315.99
</td></tr>
<tr>
<td>Cedar <i>GPU Base</i></td>
<td>172.99</td>
<td>4</td>
<td><b>662.65</b></td>
<td>595.43</td>
<td>616.02</td>
<td>490.03</td>
<td>645.04</td>
<td>608.95
</td></tr>
<tr>
<td>Cedar, <i>GPU Large</i></td>
<td>205.71</td>
<td>4</td>
<td>673.47</td>
<td>721.98</td>
<td><b>754.35</b></td>
<td>574.91</td>
<td>664.72</td>
<td>692.25
</td></tr></tbody></table>
<ul><li>VGG-16</li></ul>
<p>Lots de 32 par GPU et parallélisation des données (les résultats sont en images par seconde).
</p>
<table class="wikitable">

<tbody><tr>
<th>Type de nœud</th>
<th>1 GPU</th>
<th>Nombre de GPU</th>
<th>ps,cpu</th>
<th>ps, gpu</th>
<th>répliqué</th>
<th>répliqué, xring</th>
<th>répliqué, pscpu</th>
<th>répliqué, nccl
</th></tr>
<tr>
<td>Graham, <i>GPU Base</i></td>
<td>115.89</td>
<td>2</td>
<td>91.29</td>
<td>194.46</td>
<td>194.43</td>
<td>203.83</td>
<td>132.19</td>
<td><b>219.72</b>
</td></tr>
<tr>
<td>Cedar, <i>GPU Base</i></td>
<td>114.77</td>
<td>4</td>
<td>232.85</td>
<td>280.69</td>
<td>274.41</td>
<td>341.29</td>
<td>330.04</td>
<td><b>388.53</b>
</td></tr>
<tr>
<td>Cedar, <i>GPU Large</i></td>
<td>137.16</td>
<td>4</td>
<td>175.20</td>
<td>379.80</td>
<td>336.72</td>
<td>417.46</td>
<td>225.37</td>
<td><b>490.52</b>
</td></tr></tbody></table>
<h3><span class="mw-headline" id="TensorFlow_2.x">TensorFlow 2.x</span></h3>
<p>À l'instar de TensorFlow 1.x, TensorFlow 2.x offre des stratégies différentes pour utiliser plusieurs GPU avec l'API de haut niveau <code>tf.distribute</code>. Dans les sections qui suivent, nous montrons des exemples de code pour chacune des stratégies avec Keras. Pour plus d'information, consultez la <a rel="nofollow" class="external text" href="https://www.tensorflow.org/api_docs/python/tf/distribute">documentation officielle de TensorFlow</a>.
</p>
<h4><span id="Strat.C3.A9gie_miroir"></span><span class="mw-headline" id="Stratégie_miroir">Stratégie miroir</span></h4>
<h5><span id="N.C5.93ud_unique"></span><span class="mw-headline" id="Nœud_unique">Nœud unique</span></h5>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-singleworker.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%23SBATCH+--nodes+1%0A%23SBATCH+--gres%3Dgpu%3A4%0A%0A%23SBATCH+--mem%3D8G++++++%0A%23SBATCH+--time%3D0-00%3A30%0A%23SBATCH+--output%3D%25N-%25j.out%0A%0Amodule+load+python%2F3%0Avirtualenv+--no-download+%24SLURM_TMPDIR%2Fenv%0Asource+%24SLURM_TMPDIR%2Fenv%2Fbin%2Factivate%0Apip+install+--no-index+tensorflow%0A%0Aexport+NCCL_BLOCKING_WAIT%3D1++%23Set+this+environment+variable+if+you+wish+to+use+the+NCCL+backend+for+inter-GPU+communication.%0A%0Apython+tensorflow-singleworker.py" />
<input type="hidden" name="filename" value="tensorflow-singleworker.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes 1</span>
<span class="c1">#SBATCH --gres=gpu:4</span>

<span class="c1">#SBATCH --mem=8G      </span>
<span class="c1">#SBATCH --time=0-00:30</span>
<span class="c1">#SBATCH --output=%N-%j.out</span>

module<span class="w"> </span>load<span class="w"> </span>python/3
virtualenv<span class="w"> </span>--no-download<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/env
<span class="nb">source</span><span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/env/bin/activate
pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span>tensorflow

<span class="nb">export</span><span class="w"> </span><span class="nv">NCCL_BLOCKING_WAIT</span><span class="o">=</span><span class="m">1</span><span class="w">  </span><span class="c1">#Set this environment variable if you wish to use the NCCL backend for inter-GPU communication.</span>

python<span class="w"> </span>tensorflow-singleworker.py
</pre></div>
</div>
<p><br />
</p><p>Le script Python <code>tensorflow-singleworker.py</code> a le format
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-singleworker.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Aimport+numpy+as+np%0A%0Aimport+argparse%0A%0A%0Aparser+%3D+argparse.ArgumentParser%28description%3D%27cifar10+classification+models%2C+tensorflow+MirroredStrategy+test%27%29%0Aparser.add_argument%28%27--lr%27%2C+default%3D0.001%2C+help%3D%27%27%29%0Aparser.add_argument%28%27--batch_size%27%2C+type%3Dint%2C+default%3D256%2C+help%3D%27%27%29%0A%0Aargs+%3D+parser.parse_args%28%29%0A%0Astrategy+%3D+tf.distribute.MirroredStrategy%28%29%0A%0Awith+strategy.scope%28%29%3A%0A%0A++++model+%3D+tf.keras.Sequential%28%29%0A%0A++++model.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%2C+padding%3D%27same%27%2C%0A+++++++++++++++++input_shape%3D%2832%2C32%2C3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0A++++model.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%2C+padding%3D%27same%27%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0A++++model.add%28tf.keras.layers.Flatten%28%29%29%0A++++model.add%28tf.keras.layers.Dense%28512%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.5%29%29%0A++++model.add%28tf.keras.layers.Dense%2810%29%29%0A%0A++++model.compile%28loss%3Dtf.keras.losses.SparseCategoricalCrossentropy%28from_logits%3DTrue%29%2C%0A+++++++++optimizer%3Dtf.keras.optimizers.SGD%28learning_rate%3Dargs.lr%29%2Cmetrics%3D%5B%27accuracy%27%5D%29%0A%0A%23%23%23+This+next+line+will+attempt+to+download+the+CIFAR10+dataset+from+the+internet+if+you+don%27t+already+have+it+stored+in+%7E%2F.keras%2Fdatasets.+%0A%23%23%23+Run+this+line+on+a+login+node+prior+to+submitting+your+job%2C+or+manually+download+the+data+from+%0A%23%23%23+https%3A%2F%2Fwww.cs.toronto.edu%2F%7Ekriz%2Fcifar-10-python.tar.gz%2C+rename+to+%22cifar-10-batches-py.tar.gz%22+and+place+it+under+%7E%2F.keras%2Fdatasets%0A%0A%28x_train%2C+y_train%29%2C_+%3D+tf.keras.datasets.cifar10.load_data%28%29%0A%0Adataset+%3D+tf.data.Dataset.from_tensor_slices%28%28x_train%2C+y_train%29%29.batch%28args.batch_size%29%0A%0Amodel.fit%28dataset%2C+epochs%3D2%29" />
<input type="hidden" name="filename" value="tensorflow-singleworker.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">argparse</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;cifar10 classification models, tensorflow MirroredStrategy test&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch_size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
         <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1">### This next line will attempt to download the CIFAR10 dataset from the internet if you don&#39;t already have it stored in ~/.keras/datasets. </span>
<span class="c1">### Run this line on a login node prior to submitting your job, or manually download the data from </span>
<span class="c1">### https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz, rename to &quot;cifar-10-batches-py.tar.gz&quot; and place it under ~/.keras/datasets</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span><span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p><br />
</p>
<h5><span id="N.C5.93uds_multiples"></span><span class="mw-headline" id="Nœuds_multiples">Nœuds multiples</span></h5>
<p>La syntaxe pour utiliser des GPU distribués sur plusieurs nœuds ressemble beaucoup au cas du nœud simple; la différence principale est l'emploi de <code>MultiWorkerMirroredStrategy()</code>. Ici, nous utilisons <code>SlurmClusterResolver()</code> pour dire à TensorFlow d'obtenir par Slurm l'information sur la tâche plutôt que d'assigner manuellement un nœud principal et des nœuds secondaires (<i>workers</i>), par exemple. Nous devons aussi ajouter <code>CommunicationImplementation.NCCL</code> à la stratégie de distribution pour indiquer que nous voulons utiliser la bibliothèque NCCL de NVIDIA pour les communications entre les GPU. Ceci n'était pas nécessairement le cas pour un nœud simple puisque NCCL se trouve par défaut avec <code>MirroredStrategy()</code>.
</p><p><br />
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-multiworker.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%23SBATCH+--nodes+2++++++++++++++%23+Request+2+nodes+so+all+resources+are+in+two+nodes.%0A%23SBATCH+--gres%3Dgpu%3A2++++++++++%23+Request+2+GPU+%22generic+resources%E2%80%9D.+You+will+get+2+per+node.%0A%0A%23SBATCH+--ntasks-per-node%3D2+++%23+Request+1+process+per+GPU.+You+will+get+1+CPU+per+process+by+default.+Request+more+CPUs+with+the+%22cpus-per-task%22+parameter+if+your+input+pipeline+can+handle+parallel+data-loading%2Fdata-transforms%0A%0A%23SBATCH+--mem%3D8G++++++%0A%23SBATCH+--time%3D0-00%3A30%0A%23SBATCH+--output%3D%25N-%25j.out%0A%0A%0Asrun+-N+%24SLURM_NNODES+-n+%24SLURM_NNODES+config_env.sh%0A%0Amodule+load+gcc%2F9.3.0+cuda%2F11.8%0Aexport+NCCL_BLOCKING_WAIT%3D1++%23Set+this+environment+variable+if+you+wish+to+use+the+NCCL+backend+for+inter-GPU+communication.%0Aexport+XLA_FLAGS%3D--xla_gpu_cuda_data_dir%3D%24CUDA_HOME%0A%0Asrun+launch_training.sh" />
<input type="hidden" name="filename" value="tensorflow-multiworker.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes 2              # Request 2 nodes so all resources are in two nodes.</span>
<span class="c1">#SBATCH --gres=gpu:2          # Request 2 GPU &quot;generic resources”. You will get 2 per node.</span>

<span class="c1">#SBATCH --ntasks-per-node=2   # Request 1 process per GPU. You will get 1 CPU per process by default. Request more CPUs with the &quot;cpus-per-task&quot; parameter if your input pipeline can handle parallel data-loading/data-transforms</span>

<span class="c1">#SBATCH --mem=8G      </span>
<span class="c1">#SBATCH --time=0-00:30</span>
<span class="c1">#SBATCH --output=%N-%j.out</span>


srun<span class="w"> </span>-N<span class="w"> </span><span class="nv">$SLURM_NNODES</span><span class="w"> </span>-n<span class="w"> </span><span class="nv">$SLURM_NNODES</span><span class="w"> </span>config_env.sh

module<span class="w"> </span>load<span class="w"> </span>gcc/9.3.0<span class="w"> </span>cuda/11.8
<span class="nb">export</span><span class="w"> </span><span class="nv">NCCL_BLOCKING_WAIT</span><span class="o">=</span><span class="m">1</span><span class="w">  </span><span class="c1">#Set this environment variable if you wish to use the NCCL backend for inter-GPU communication.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">XLA_FLAGS</span><span class="o">=</span>--xla_gpu_cuda_data_dir<span class="o">=</span><span class="nv">$CUDA_HOME</span>

srun<span class="w"> </span>launch_training.sh
</pre></div>
</div>
<p><br />
</p><p>où <code>config_env.sh</code> a la forme
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> config_env.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%0Amodule+load+python%0A%0Avirtualenv+--no-download+%24SLURM_TMPDIR%2FENV%0A%0Asource+%24SLURM_TMPDIR%2FENV%2Fbin%2Factivate%0A%0Apip+install+--upgrade+pip+--no-index%0A%0Apip+install+--no-index+tensorflow%0A%0Aecho+%22Done+installing+virtualenv%21%22" />
<input type="hidden" name="filename" value="config_env.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>

module<span class="w"> </span>load<span class="w"> </span>python

virtualenv<span class="w"> </span>--no-download<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/ENV

<span class="nb">source</span><span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/ENV/bin/activate

pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip<span class="w"> </span>--no-index

pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span>tensorflow

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Done installing virtualenv!&quot;</span>
</pre></div>
</div>
<p><br />
</p><p>Le script <code>launch_training.sh</code> a la forme
</p><p><br />
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> launch_training.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%0Asource+%24SLURM_TMPDIR%2FENV%2Fbin%2Factivate%0A%0Apython+tensorflow-multiworker.py" />
<input type="hidden" name="filename" value="launch_training.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="nb">source</span><span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/ENV/bin/activate

python<span class="w"> </span>tensorflow-multiworker.py
</pre></div>
</div>
<p><br />
</p><p>Le script Python <code>tensorflow-multiworker.py</code> a la forme suivante&#160;:
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-multiworker.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Aimport+numpy+as+np%0A%0Aimport+argparse%0A%0A%0Aparser+%3D+argparse.ArgumentParser%28description%3D%27cifar10+classification+models%2C+tensorflow+MultiWorkerMirrored+test%27%29%0Aparser.add_argument%28%27--lr%27%2C+default%3D0.001%2C+help%3D%27%27%29%0Aparser.add_argument%28%27--batch_size%27%2C+type%3Dint%2C+default%3D256%2C+help%3D%27%27%29%0A%0Aargs+%3D+parser.parse_args%28%29%0A%0Acluster_config+%3D+tf.distribute.cluster_resolver.SlurmClusterResolver%28%29%0Acomm_options+%3D+tf.distribute.experimental.CommunicationOptions%28implementation%3Dtf.distribute.experimental.CommunicationImplementation.NCCL%29%0A%0Astrategy+%3D+tf.distribute.MultiWorkerMirroredStrategy%28cluster_resolver%3Dcluster_config%2C+communication_options%3Dcomm_options%29%0A%0Awith+strategy.scope%28%29%3A%0A%0A++++model+%3D+tf.keras.Sequential%28%29%0A%0A++++model.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%2C+padding%3D%27same%27%2C%0A+++++++++++++++++input_shape%3D%2832%2C32%2C3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0A++++model.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%2C+padding%3D%27same%27%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0A++++model.add%28tf.keras.layers.Flatten%28%29%29%0A++++model.add%28tf.keras.layers.Dense%28512%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.5%29%29%0A++++model.add%28tf.keras.layers.Dense%2810%29%29%0A%0A++++model.compile%28loss%3Dtf.keras.losses.SparseCategoricalCrossentropy%28from_logits%3DTrue%29%2C%0A+++++++++optimizer%3Dtf.keras.optimizers.SGD%28learning_rate%3Dargs.lr%29%2Cmetrics%3D%5B%27accuracy%27%5D%29%0A%0A%23%23%23+This+next+line+will+attempt+to+download+the+CIFAR10+dataset+from+the+internet+if+you+don%27t+already+have+it+stored+in+%7E%2F.keras%2Fdatasets.+%0A%23%23%23+Run+this+line+on+a+login+node+prior+to+submitting+your+job%2C+or+manually+download+the+data+from+%0A%23%23%23+https%3A%2F%2Fwww.cs.toronto.edu%2F%7Ekriz%2Fcifar-10-python.tar.gz%2C+rename+to+%22cifar-10-batches-py.tar.gz%22+and+place+it+under+%7E%2F.keras%2Fdatasets%0A%0A%28x_train%2C+y_train%29%2C_+%3D+tf.keras.datasets.cifar10.load_data%28%29%0A%0Adataset+%3D+tf.data.Dataset.from_tensor_slices%28%28x_train%2C+y_train%29%29.batch%28args.batch_size%29%0A%0Amodel.fit%28dataset%2C+epochs%3D2%29" />
<input type="hidden" name="filename" value="tensorflow-multiworker.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">argparse</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;cifar10 classification models, tensorflow MultiWorkerMirrored test&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch_size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">cluster_config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">SlurmClusterResolver</span><span class="p">()</span>
<span class="n">comm_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">CommunicationOptions</span><span class="p">(</span><span class="n">implementation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">CommunicationImplementation</span><span class="o">.</span><span class="n">NCCL</span><span class="p">)</span>

<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">(</span><span class="n">cluster_resolver</span><span class="o">=</span><span class="n">cluster_config</span><span class="p">,</span> <span class="n">communication_options</span><span class="o">=</span><span class="n">comm_options</span><span class="p">)</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
         <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1">### This next line will attempt to download the CIFAR10 dataset from the internet if you don&#39;t already have it stored in ~/.keras/datasets. </span>
<span class="c1">### Run this line on a login node prior to submitting your job, or manually download the data from </span>
<span class="c1">### https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz, rename to &quot;cifar-10-batches-py.tar.gz&quot; and place it under ~/.keras/datasets</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span><span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p><br />
</p>
<h4><span class="mw-headline" id="Horovod">Horovod</span></h4>
<p><a rel="nofollow" class="external text" href="https://horovod.readthedocs.io/en/latest/summary_include.html">Horovod</a> est une bibliothèque d'apprentissage profond distribué pour TensorFlow, Keras, PyTorch et Apache MXNet. Nous reprenons le même tutoriel que ci-dessus, cette fois-ci avec Horovod.
</p><p><br />
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-horovod.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%23SBATCH+--nodes+1+++++++++++++%0A%23SBATCH+--gres%3Dgpu%3A2++++++++++%23+Request+2+GPU+%22generic+resources%E2%80%9D.+You+will+get+2+per+node.%0A%0A%23SBATCH+--ntasks-per-node%3D2++++%23+Request+1+process+per+GPU.+You+will+get+1+CPU+per+process+by+default.+Request+more+CPUs+with+the+%22cpus-per-task%22+parameter+if+your+input+pipeline+can+handle+parallel+data-loading%2Fdata-transforms%0A%0A%23SBATCH+--mem%3D8G++++++%0A%23SBATCH+--time%3D0-00%3A30%0A%23SBATCH+--output%3D%25N-%25j.out%0A%0A%0Amodule+load+StdEnv%2F2020+%0Amodule+load+python%2F3.8%0Avirtualenv+--no-download+%24SLURM_TMPDIR%2Fenv%0Asource+%24SLURM_TMPDIR%2Fenv%2Fbin%2Factivate%0Apip+install+--no-index+tensorflow%3D%3D2.5.0+horovod%0A%0Aexport+NCCL_BLOCKING_WAIT%3D1++%23Set+this+environment+variable+if+you+wish+to+use+the+NCCL+backend+for+inter-GPU+communication.%0A%0Asrun+python+tensorflow-horovod.py" />
<input type="hidden" name="filename" value="tensorflow-horovod.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes 1             </span>
<span class="c1">#SBATCH --gres=gpu:2          # Request 2 GPU &quot;generic resources”. You will get 2 per node.</span>

<span class="c1">#SBATCH --ntasks-per-node=2    # Request 1 process per GPU. You will get 1 CPU per process by default. Request more CPUs with the &quot;cpus-per-task&quot; parameter if your input pipeline can handle parallel data-loading/data-transforms</span>

<span class="c1">#SBATCH --mem=8G      </span>
<span class="c1">#SBATCH --time=0-00:30</span>
<span class="c1">#SBATCH --output=%N-%j.out</span>


module<span class="w"> </span>load<span class="w"> </span>StdEnv/2020<span class="w"> </span>
module<span class="w"> </span>load<span class="w"> </span>python/3.8
virtualenv<span class="w"> </span>--no-download<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/env
<span class="nb">source</span><span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/env/bin/activate
pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span><span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.5.0<span class="w"> </span>horovod

<span class="nb">export</span><span class="w"> </span><span class="nv">NCCL_BLOCKING_WAIT</span><span class="o">=</span><span class="m">1</span><span class="w">  </span><span class="c1">#Set this environment variable if you wish to use the NCCL backend for inter-GPU communication.</span>

srun<span class="w"> </span>python<span class="w"> </span>tensorflow-horovod.py
</pre></div>
</div>
<p><br />
</p><p><br />
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-horovod.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Aimport+numpy+as+np%0Aimport+horovod.tensorflow.keras+as+hvd%0A%0Aimport+argparse%0A%0A%0Aparser+%3D+argparse.ArgumentParser%28description%3D%27cifar10+classification+models%2C+tensorflow+horovod+test%27%29%0Aparser.add_argument%28%27--lr%27%2C+default%3D0.001%2C+help%3D%27%27%29%0Aparser.add_argument%28%27--batch_size%27%2C+type%3Dint%2C+default%3D256%2C+help%3D%27%27%29%0A%0Aargs+%3D+parser.parse_args%28%29%0A%0Ahvd.init%28%29%0A%0Agpus+%3D+tf.config.experimental.list_physical_devices%28%27GPU%27%29%0A%0Atf.config.experimental.set_visible_devices%28gpus%5Bhvd.local_rank%28%29%5D%2C+%27GPU%27%29%0A%0Amodel+%3D+tf.keras.Sequential%28%29%0A%0Amodel.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%2C+padding%3D%27same%27%2C%0A+++++++++++++++++input_shape%3D%2832%2C32%2C3%29%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0Amodel.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0Amodel.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%2C+padding%3D%27same%27%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0Amodel.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0Amodel.add%28tf.keras.layers.Flatten%28%29%29%0Amodel.add%28tf.keras.layers.Dense%28512%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.Dropout%280.5%29%29%0Amodel.add%28tf.keras.layers.Dense%2810%29%29%0A%0Aoptimizer+%3D+tf.keras.optimizers.SGD%28learning_rate%3Dargs.lr%29%0A%0Aoptimizer+%3D+hvd.DistributedOptimizer%28optimizer%29%0A%0Amodel.compile%28loss%3Dtf.keras.losses.SparseCategoricalCrossentropy%28from_logits%3DTrue%29%2C%0A+++++++++optimizer%3Doptimizer%2Cmetrics%3D%5B%27accuracy%27%5D%29%0A%0Acallbacks+%3D+%5B%0A++++hvd.callbacks.BroadcastGlobalVariablesCallback%280%29%2C%0A%5D%0A%0A%23%23%23+This+next+line+will+attempt+to+download+the+CIFAR10+dataset+from+the+internet+if+you+don%27t+already+have+it+stored+in+%7E%2F.keras%2Fdatasets.+%0A%23%23%23+Run+this+line+on+a+login+node+prior+to+submitting+your+job%2C+or+manually+download+the+data+from+%0A%23%23%23+https%3A%2F%2Fwww.cs.toronto.edu%2F%7Ekriz%2Fcifar-10-python.tar.gz%2C+rename+to+%22cifar-10-batches-py.tar.gz%22+and+place+it+under+%7E%2F.keras%2Fdatasets%0A%0A%28x_train%2C+y_train%29%2C_+%3D+tf.keras.datasets.cifar10.load_data%28%29%0A%0Adataset+%3D+tf.data.Dataset.from_tensor_slices%28%28x_train%2C+y_train%29%29.batch%28args.batch_size%29%0A%0Amodel.fit%28dataset%2C+epochs%3D2%2C+callbacks%3Dcallbacks%2C+verbose%3D2%29+%23+verbose%3D2+to+avoid+printing+a+progress+bar+to+%2A.out+files." />
<input type="hidden" name="filename" value="tensorflow-horovod.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">horovod.tensorflow.keras</span> <span class="k">as</span> <span class="nn">hvd</span>

<span class="kn">import</span> <span class="nn">argparse</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;cifar10 classification models, tensorflow horovod test&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch_size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">hvd</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">(</span><span class="n">gpus</span><span class="p">[</span><span class="n">hvd</span><span class="o">.</span><span class="n">local_rank</span><span class="p">()],</span> <span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">DistributedOptimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
         <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">hvd</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">BroadcastGlobalVariablesCallback</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="p">]</span>

<span class="c1">### This next line will attempt to download the CIFAR10 dataset from the internet if you don&#39;t already have it stored in ~/.keras/datasets. </span>
<span class="c1">### Run this line on a login node prior to submitting your job, or manually download the data from </span>
<span class="c1">### https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz, rename to &quot;cifar-10-batches-py.tar.gz&quot; and place it under ~/.keras/datasets</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span><span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># verbose=2 to avoid printing a progress bar to *.out files.</span>
</pre></div>
</div>
<p><br />
</p>
<h2><span id="Cr.C3.A9er_des_points_de_contr.C3.B4le"></span><span class="mw-headline" id="Créer_des_points_de_contrôle">Créer des points de contrôle</span></h2>
<p>Peu importe le temps que dure l'exécution de votre code, une bonne habitude à prendre est de créer des points de contrôle pendant l'entraînement. Un point de contrôle vous donne le portrait de votre modèle à un moment précis du processus d'entraînement (après un certain nombre d'itérations ou d'époques); le portrait est enregistré sur disque et vous pourrez le récupérer par la suite. Ceci est pratique pour diviser en petites tâches une tâche qui doit avoir un long temps d'exécution, ce qui pourrait faire qu'elles soient être allouées plus rapidement à une grappe. C'est aussi un bon moyen d'éviter de perdre votre travail en cas d'erreurs inattendues ou de panne du matériel.
</p>
<h3><span class="mw-headline" id="Avec_Keras">Avec Keras</span></h3>
<p>Pour créer un point de contrôle dans un entraînement avec <code>keras</code>, nous recommandons le paramètre <code>callbacks</code> de la méthode <code>model.fit()</code>. Dans l'exemple suivant, nous demandons à TensorFlow de créer un point de contrôle à la fin de chacune des époques d'entraînement.
</p>
<pre>callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath="./ckpt",save_freq="epoch")] # Make sure the path where you want to create the checkpoint exists

model.fit(dataset, epochs=10 , callbacks=callbacks)
</pre>
<p>Pour plus d'information, consultez la <a rel="nofollow" class="external text" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint">documentation officielle de TensorFlow</a>.
</p>
<h3><span id="Avec_une_boucle_d.27entra.C3.AEnement_personnalis.C3.A9e"></span><span class="mw-headline" id="Avec_une_boucle_d'entraînement_personnalisée">Avec une boucle d'entraînement personnalisée</span></h3>
<p>Voyez la <a rel="nofollow" class="external text" href="https://www.tensorflow.org/guide/checkpoint#writing_checkpoints">documentation officielle de TensorFlow</a>.
</p>
<h2><span id="Op.C3.A9rateurs_personnalis.C3.A9s"></span><span class="mw-headline" id="Opérateurs_personnalisés">Opérateurs personnalisés</span></h2>
<p>Dans le cadre de votre recherche, vous pourriez avoir besoin d'utiliser <a rel="nofollow" class="external text" href="https://github.com/Yang7879/3D-BoNet">du code pour tirer avantage des opérateurs personnalisés</a> qui ne sont pas inclus dans les distributions de TensorFlow, ou même vouloir <a rel="nofollow" class="external text" href="https://www.tensorflow.org/guide/create_op">créer vos propres opérateurs personnalisés</a>. Dans les deux cas, vos opérateurs personnalisés doivent être compilés avant que vous soumettiez la tâche. Suivez les étapes ci-dessous.
</p><p>Créez d'abord un <a href="/wiki/Python/fr" title="Python/fr">environnement virtuel Python</a> et installez une version de TensorFlow compatible avec vos opérateurs personnalisés. Allez ensuite au répertoire qui contient le code source des opérateurs et utilisez les commandes qui suivent selon la version que vous avez installée.
</p>
<h3><span id="TensorFlow_.3C.3D_1.4.x"></span><span class="mw-headline" id="TensorFlow_&lt;=_1.4.x">TensorFlow &lt;= 1.4.x</span></h3>
<p>Si votre opérateur personnalisé <b>peut prendre en charge</b> un GPU&#160;:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>cuda/&lt;version&gt;
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>nvcc<span class="w"> </span>&lt;operator&gt;.cu<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.cu.o<span class="w"> </span>-c<span class="w"> </span>-O2<span class="w"> </span>-DGOOGLE_CUDA<span class="o">=</span><span class="m">1</span><span class="w"> </span>-x<span class="w"> </span>cu<span class="w"> </span>-Xcompiler<span class="w"> </span>-fPI
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>&lt;operator&gt;.cpp<span class="w"> </span>&lt;operator&gt;.cu.o<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.so<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include<span class="w"> </span>-I/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include/external/nsync/public<span class="w"> </span>-I<span class="w"> </span>/usr/local/cuda-&lt;version&gt;/include<span class="w"> </span>-lcudart<span class="w"> </span>-L<span class="w"> </span>/usr/local/cuda-&lt;version&gt;/lib64/
</pre></div></div>
<p><br />
Si votre opérateur personnalisé <b>ne peut pas prendre en charge</b> un GPU&#160;:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>&lt;operator&gt;.cpp<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.so<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include<span class="w"> </span>-I/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include/external/nsync/public
</pre></div></div>
<p><br />
</p>
<h3><span id="TensorFlow_.3E_1.4.x"></span><span class="mw-headline" id="TensorFlow_&gt;_1.4.x">TensorFlow &gt; 1.4.x</span></h3>
<p>Si votre opérateur personnalisé <b>peut prendre en charge</b> un GPU&#160;:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>cuda/&lt;version&gt;
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>nvcc<span class="w"> </span>&lt;operator&gt;.cu<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.cu.o<span class="w"> </span>-c<span class="w"> </span>-O2<span class="w"> </span>-DGOOGLE_CUDA<span class="o">=</span><span class="m">1</span><span class="w"> </span>-x<span class="w"> </span>cu<span class="w"> </span>-Xcompiler<span class="w"> </span>-fPI
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>&lt;operator&gt;.cpp<span class="w"> </span>&lt;operator&gt;.cu.o<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.so<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include<span class="w"> </span>-I<span class="w"> </span>/usr/local/cuda-&lt;version&gt;/include<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include/external/nsync/public<span class="w"> </span>-lcudart<span class="w"> </span>-L<span class="w"> </span>/usr/local/cuda-&lt;version&gt;/lib64/<span class="w"> </span>-L<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow<span class="w"> </span>-ltensorflow_framework
</pre></div></div>
<p><br />
Si votre opérateur personnalisé <b>ne peut pas prendre en charge</b> un GPU&#160;:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>&lt;operator&gt;.cpp<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.so<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include/external/nsync/public<span class="w"> </span>-L<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow<span class="w"> </span>-ltensorflow_framework
</pre></div></div>
<p><br />
</p>
<h2><span id="D.C3.A9pannage"></span><span class="mw-headline" id="Dépannage">Dépannage</span></h2>
<h3><span class="mw-headline" id="scikit-image">scikit-image</span></h3>
<p>Si vous utilisez la bibliothèque scikit-image, vous pourriez recevoir l'erreur
<code>OMP: Error #15: Initializing libiomp5.so, but found libiomp5.so already initialized. </code>
</p><p>Ceci se produit quand la bibliothèque TensorFlow essaie de charger une version de OMP incompatible avec la version du système. Pour contourner ceci&#160;:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">(</span>tf_skimage_venv<span class="o">)</span><span class="w"> </span>name@server<span class="w"> </span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>tf_skimage_venv
<span class="o">(</span>tf_skimage_venv<span class="o">)</span><span class="w"> </span>name@server<span class="w"> </span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">LIBIOMP_PATH</span><span class="o">=</span><span class="k">$(</span>strace<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;from skimage.transform import AffineTransform&#39;</span><span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-v<span class="w"> </span>ENOENT<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-ohP<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;(?&lt;=&quot;)[^&quot;]+libiomp5.so(?=&quot;)&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>realpath<span class="k">)</span>
<span class="o">(</span>tf_skimage_venv<span class="o">)</span><span class="w"> </span>name@server<span class="w"> </span>$<span class="w"> </span>find<span class="w"> </span>-path<span class="w"> </span><span class="s1">&#39;*_solib_local*&#39;</span><span class="w"> </span>-name<span class="w"> </span>libiomp5.so<span class="w"> </span>-exec<span class="w"> </span>ln<span class="w"> </span>-sf<span class="w"> </span><span class="nv">$LIBIOMP_PATH</span><span class="w"> </span><span class="o">{}</span><span class="w"> </span><span class="se">\;</span>
</pre></div></div>
<p>L'installation de la bibliothèque TensorFlow pourra alors utiliser libiomp5.so.
</p>
<h3><span class="mw-headline" id="libcupti.so">libcupti.so</span></h3>
<p>Certaines fonctions de suivi de TensorFlow utilisent la bibliothèque libcupti.so; si cette dernière n'est pas disponible, l'erreur suivante pourrait survenir&#160;:
</p><p><code>I tensorflow/stream_executor/dso_loader.cc:142] Couldn't open CUDA library libcupti.so.9.0. LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64</code>
</p><p>La solution est d'exécuter les commandes suivantes avant l'exécution du script.
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>cuda/9.0.xxx
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:<span class="nv">$CUDA_HOME</span>/extras/CUPTI/lib64/
</pre></div></div>
<p>Remplacez xxx par la version appropriée de CUDA que vous pouvez trouver avec <code>module av cuda</code>.
</p>
<h3><span class="mw-headline" id="libiomp5.so_invalid_ELF_header">libiomp5.so invalid ELF header</span></h3>
<p>Le fichier objet partagé <code>libiomp5.so</code> est quelquefois par erreur installé en tant que fichier texte, ce qui peut produire des erreurs comme ceci&#160;:
</p><p><code>/home/username/venv/lib/python3.6/site-packages/tensorflow/python/../../_solib_local/_U@mkl_Ulinux_S_S_Cmkl_Ulibs_Ulinux___Uexternal_Smkl_Ulinux_Slib/libiomp5.so: invalid ELF header</code>
</p><p>Pour solutionner ces erreurs, accédez au répertoire indiqué dans le message (soit <code>[...]/_U@mkl_Ulinux_S_S_Cmkl_Ulibs_Ulinux___Uexternal_Smkl_Ulinux_Slib</code>) et lancez la commande
</p>
<div>
<div style="float:right; margin-left:8px">
<p><span typeof="mw:File"><a href="https://explainshell.com/explain?cmd=ln+-sf+%24%28cat+libiomp5.so%29+libiomp5.so" rel="nofollow"><img src="/mediawiki/images/thumb/3/30/Question.png/40px-Question.png" decoding="async" width="40" height="40" class="mw-file-element" srcset="/mediawiki/images/thumb/3/30/Question.png/60px-Question.png 1.5x, /mediawiki/images/thumb/3/30/Question.png/80px-Question.png 2x" /></a></span>
</p>
</div>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>...Ulinux_Slib<span class="o">]</span><span class="w"> </span>$<span class="w"> </span>ln<span class="w"> </span>-sf<span class="w"> </span><span class="k">$(</span>cat<span class="w"> </span>libiomp5.so<span class="k">)</span><span class="w"> </span>libiomp5.so
</pre></div>
</div>
</div>
<p>Le fichier texte sera remplacé par le bon lien symbolique.
</p>
<h2><span id="Contr.C3.B4le_du_nombre_de_CPU_et_de_fils"></span><span class="mw-headline" id="Contrôle_du_nombre_de_CPU_et_de_fils">Contrôle du nombre de CPU et de fils</span></h2>
<h3><span class="mw-headline" id="TensorFlow_1.x_2">TensorFlow 1.x</span></h3>
<p>Les paramètres de configuration  <code>device_count</code>, <code>intra_op_parallelism_threads</code> et <code>inter_op_parallelism_threads</code> ont un effet sur le nombre de fils utilisés par TensorFlow; ces paramètres peuvent être définis comme suit à l'instanciation d'une session&#160;:
</p>
<pre>tf.Session(config=tf.ConfigProto(device_count={'CPU': num_cpus}, intra_op_parallelism_threads=num_intra_threads, inter_op_parallelism_threads=num_inter_threads))
</pre>
<p>Si par exemple vous voulez exécuter plusieurs instances en parallèle dans un seul nœud, vous pourriez devoir utiliser de plus petites valeurs et même diminuer jusqu'à <code>1</code>.
</p>
<h3><span class="mw-headline" id="TensorFlow_2.x_2">TensorFlow 2.x</span></h3>
<p>Puisque les sessions ne sont plus utilisées, la configuration des fils se fait comme suit&#160;:
</p>
<pre>tf.config.threading.set_inter_op_parallelism_threads(num_threads)
tf.config.threading.set_intra_op_parallelism_threads(num_threads)
</pre>
<p>Il ne semble pas possible de définir un nombre de CPU depuis la version 2.1.
</p>
<h2><span id="Probl.C3.A8mes_connus"></span><span class="mw-headline" id="Problèmes_connus">Problèmes connus</span></h2>
<p>Un bogue s'est introduit dans l'implémentation Keras de Tensorflow après la version 2.8.3. Il affecte la performance des layers d'augmentation des données <i>tf.keras.layers.Random</i> (comme <i>tf.keras.layers.RandomRotation</i>, <i>tf.keras.layers.RandomTranslation</i>, etc.). Le processus d'entraînement est ralenti d'un facteur de plus de 100. <b>Ce bogue a été corrigé dans la version 2.12.
</b></p>
<!-- 
NewPP limit report
Cached time: 20250530235337
Cache expiry: 86400
Reduced expiry: false
Complications: [show‐toc]
CPU time usage: 0.105 seconds
Real time usage: 0.209 seconds
Preprocessor visited node count: 1319/1000000
Post‐expand include size: 24821/2097152 bytes
Template argument size: 23010/2097152 bytes
Highest expansion depth: 8/100
Expensive parser function count: 36/100
Unstrip recursion depth: 3/20
Unstrip post‐expand size: 90254/5000000 bytes
ExtLoops count: 0/100
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  130.982      1 -total
 85.28%  111.696     13 Template:File
  1.67%    2.186     14 Template:Command2
  1.44%    1.885      6 Template:Commands
  0.39%    0.506      1 Template:Command
-->

<!-- Saved in parser cache with key ccwiki:pcache:idhash:3617-0!canonical and timestamp 20250530235337 and revision id 157643. Rendering was triggered because: page-view
 -->
</div>
<div class="printfooter" data-nosnippet="">Retrieved from "<a dir="ltr" href="https://docs.alliancecan.ca/mediawiki/index.php?title=TensorFlow/fr&amp;oldid=157643">https://docs.alliancecan.ca/mediawiki/index.php?title=TensorFlow/fr&amp;oldid=157643</a>"</div></div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>: <ul><li><a href="/wiki/Category:Software" title="Category:Software">Software</a></li><li><a href="/wiki/Category:AI_and_Machine_Learning" title="Category:AI and Machine Learning">AI and Machine Learning</a></li></ul></div></div>
	</div>
</div>

<div id="mw-navigation">
	<h2>Navigation menu</h2>
	<div id="mw-head">
		
<nav id="p-personal" class="mw-portlet mw-portlet-personal vector-user-menu-legacy vector-menu" aria-labelledby="p-personal-label"  >
	<h3
		id="p-personal-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Personal tools</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-uls" class="mw-list-item active"><a class="uls-trigger" href="#"><span>English</span></a></li><li id="pt-login" class="mw-list-item"><a href="/mediawiki/index.php?title=Special:UserLogin&amp;returnto=TensorFlow%2Ffr" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o"><span>Log in</span></a></li>
		</ul>
		
	</div>
</nav>

		<div id="left-navigation">
			
<nav id="p-namespaces" class="mw-portlet mw-portlet-namespaces vector-menu-tabs vector-menu-tabs-legacy vector-menu" aria-labelledby="p-namespaces-label"  >
	<h3
		id="p-namespaces-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Namespaces</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-nstab-main" class="selected mw-list-item"><a href="/wiki/TensorFlow/fr" title="View the content page [c]" accesskey="c"><span>Page</span></a></li><li id="ca-talk" class="new mw-list-item"><a href="/mediawiki/index.php?title=Talk:TensorFlow/fr&amp;action=edit&amp;redlink=1" rel="discussion" class="new" title="Discussion about the content page (page does not exist) [t]" accesskey="t"><span>Discussion</span></a></li>
		</ul>
		
	</div>
</nav>

			
<nav id="p-variants" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu-dropdown vector-menu" aria-labelledby="p-variants-label"  >
	<input type="checkbox"
		id="p-variants-checkbox"
		role="button"
		aria-haspopup="true"
		data-event-name="ui.dropdown-p-variants"
		class="vector-menu-checkbox"
		aria-labelledby="p-variants-label"
	>
	<label
		id="p-variants-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">français</span>
	</label>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</nav>

		</div>
		<div id="right-navigation">
			
<nav id="p-views" class="mw-portlet mw-portlet-views vector-menu-tabs vector-menu-tabs-legacy vector-menu" aria-labelledby="p-views-label"  >
	<h3
		id="p-views-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Views</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-view" class="selected mw-list-item"><a href="/wiki/TensorFlow/fr"><span>Read</span></a></li><li id="ca-viewsource" class="mw-list-item"><a href="/mediawiki/index.php?title=TensorFlow/fr&amp;action=edit" title="This page is protected.&#10;You can view its source [e]" accesskey="e"><span>View source</span></a></li><li id="ca-history" class="mw-list-item"><a href="/mediawiki/index.php?title=TensorFlow/fr&amp;action=history" title="Past revisions of this page [h]" accesskey="h"><span>View history</span></a></li>
		</ul>
		
	</div>
</nav>

			
<nav id="p-cactions" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu-dropdown vector-menu" aria-labelledby="p-cactions-label"  title="More options" >
	<input type="checkbox"
		id="p-cactions-checkbox"
		role="button"
		aria-haspopup="true"
		data-event-name="ui.dropdown-p-cactions"
		class="vector-menu-checkbox"
		aria-labelledby="p-cactions-label"
	>
	<label
		id="p-cactions-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">More</span>
	</label>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</nav>

			
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<h3 >Search</h3>
	<form action="/mediawiki/index.php" id="searchform" class="vector-search-box-form">
		<div id="simpleSearch"
			class="vector-search-box-inner"
			 data-search-loc="header-navigation">
			<input class="vector-search-box-input"
				 type="search" name="search" placeholder="Search Alliance Doc" aria-label="Search Alliance Doc" autocapitalize="sentences" title="Search Alliance Doc [f]" accesskey="f" id="searchInput"
			>
			<input type="hidden" name="title" value="Special:Search">
			<input id="mw-searchButton"
				 class="searchButton mw-fallbackSearchButton" type="submit" name="fulltext" title="Search the pages for this text" value="Search">
			<input id="searchButton"
				 class="searchButton" type="submit" name="go" title="Go to a page with this exact name if it exists" value="Go">
		</div>
	</form>
</div>

		</div>
	</div>
	
<div id="mw-panel" class="vector-legacy-sidebar">
	<div id="p-logo" role="banner">
		<a class="mw-wiki-logo" href="/wiki/Technical_documentation"
			title="Visit the main page"></a>
	</div>
	
<nav id="p-navigation" class="mw-portlet mw-portlet-navigation vector-menu-portal portal vector-menu" aria-labelledby="p-navigation-label"  >
	<h3
		id="p-navigation-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Navigation</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-sidebar-wiki-main-page" class="mw-list-item"><a href="/wiki/Technical_documentation"><span>Wiki Main Page</span></a></li>
		</ul>
		
	</div>
</nav>

	
<nav id="p-sidebar-support" class="mw-portlet mw-portlet-sidebar-support vector-menu-portal portal vector-menu" aria-labelledby="p-sidebar-support-label"  >
	<h3
		id="p-sidebar-support-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Support</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-sidebar-getting-started" class="mw-list-item"><a href="/wiki/Getting_started"><span>Getting started</span></a></li><li id="n-sidebar-technical-support" class="mw-list-item"><a href="/wiki/Technical_support"><span>Getting help</span></a></li><li id="n-sidebar-running-jobs" class="mw-list-item"><a href="/wiki/Running_jobs"><span>Running jobs</span></a></li><li id="n-sidebar-known-issues" class="mw-list-item"><a href="/wiki/Known_issues"><span>Known issues</span></a></li><li id="n-sidebar-system-status" class="mw-list-item"><a href="http://status.computecanada.ca" rel="nofollow"><span>System status</span></a></li>
		</ul>
		
	</div>
</nav>

<nav id="p-sidebar-resources" class="mw-portlet mw-portlet-sidebar-resources vector-menu-portal portal vector-menu" aria-labelledby="p-sidebar-resources-label"  >
	<h3
		id="p-sidebar-resources-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Resources</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-Béluga" class="mw-list-item"><a href="/wiki/B%C3%A9luga/en"><span>Béluga</span></a></li><li id="n-Cedar" class="mw-list-item"><a href="/wiki/Cedar"><span>Cedar</span></a></li><li id="n-Graham" class="mw-list-item"><a href="/wiki/Graham"><span>Graham</span></a></li><li id="n-Narval" class="mw-list-item"><a href="/wiki/Narval/en"><span>Narval</span></a></li><li id="n-Niagara" class="mw-list-item"><a href="/wiki/Niagara"><span>Niagara</span></a></li><li id="n-sidebar-cloud" class="mw-list-item"><a href="/wiki/CC-Cloud"><span>Cloud</span></a></li><li id="n-tamIA" class="mw-list-item"><a href="/wiki/TamIA/en"><span>tamIA</span></a></li><li id="n-Killarney" class="mw-list-item"><a href="/wiki/Killarney"><span>Killarney</span></a></li><li id="n-sidebar-quantum-computing" class="mw-list-item"><a href="/wiki/Services_d%27informatique_quantique/en"><span>Quantum computing</span></a></li><li id="n-sidebar-available-software" class="mw-list-item"><a href="/wiki/Available_software"><span>Available software</span></a></li>
		</ul>
		
	</div>
</nav>

<nav id="p-sidebar-alliance" class="mw-portlet mw-portlet-sidebar-alliance vector-menu-portal portal vector-menu" aria-labelledby="p-sidebar-alliance-label"  >
	<h3
		id="p-sidebar-alliance-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">The Alliance</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-sidebar-alliance-main-page" class="mw-list-item"><a href="https://alliancecan.ca/en" rel="nofollow"><span>Alliance main page</span></a></li><li id="n-sidebar-ccdb" class="mw-list-item"><a href="https://ccdb.computecanada.ca/security/login" rel="nofollow"><span>CCDB</span></a></li><li id="n-sidebar-getting-an-account" class="mw-list-item"><a href="https://alliancecan.ca/en/services/advanced-research-computing/account-management/apply-account" rel="nofollow"><span>Getting An Account</span></a></li><li id="n-sidebar-acknowledging-alliance" class="mw-list-item"><a href="https://alliancecan.ca/en/services/advanced-research-computing/research-portal/acknowledging-alliance" rel="nofollow"><span>Acknowledging the Alliance</span></a></li><li id="n-sidebar-aup" class="mw-list-item"><a href="https://alliancecan.ca/en/services/advanced-research-computing/account-management/policies" rel="nofollow"><span>Acceptable Use Policy</span></a></li>
		</ul>
		
	</div>
</nav>

<nav id="p-sidebar-authoring" class="mw-portlet mw-portlet-sidebar-authoring vector-menu-portal portal vector-menu" aria-labelledby="p-sidebar-authoring-label"  >
	<h3
		id="p-sidebar-authoring-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Authoring</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-sidebar-guidelines" class="mw-list-item"><a href="/wiki/Authoring_guidelines"><span>Guidelines</span></a></li><li id="n-sidebar-mediawiki-help" class="mw-list-item"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/Help:Contents"><span>MediaWiki Help</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r"><span>Recent changes</span></a></li>
		</ul>
		
	</div>
</nav>

<nav id="p-tb" class="mw-portlet mw-portlet-tb vector-menu-portal portal vector-menu" aria-labelledby="p-tb-label"  >
	<h3
		id="p-tb-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Tools</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="t-whatlinkshere" class="mw-list-item"><a href="/wiki/Special:WhatLinksHere/TensorFlow/fr" title="A list of all wiki pages that link here [j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="/wiki/Special:RecentChangesLinked/TensorFlow/fr" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k"><span>Related changes</span></a></li><li id="t-specialpages" class="mw-list-item"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q"><span>Special pages</span></a></li><li id="t-print" class="mw-list-item"><a href="javascript:print();" rel="alternate" title="Printable version of this page [p]" accesskey="p"><span>Printable version</span></a></li><li id="t-permalink" class="mw-list-item"><a href="/mediawiki/index.php?title=TensorFlow/fr&amp;oldid=157643" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="/mediawiki/index.php?title=TensorFlow/fr&amp;action=info" title="More information about this page"><span>Page information</span></a></li>
		</ul>
		
	</div>
</nav>

	
</div>

</div>

<footer id="footer" class="mw-footer" >
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 15 July 2024, at 19:36.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="/wiki/CCWiki:Privacy_policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="/wiki/CCWiki:About">About Alliance Doc</a></li>
	<li id="footer-places-disclaimers"><a href="/wiki/CCWiki:General_disclaimer">Disclaimers</a></li>
	<li id="footer-places-mobileview"><a href="https://docs.alliancecan.ca/mediawiki/index.php?title=TensorFlow/fr&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
</ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/" class="cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled"><img src="/mediawiki/resources/assets/poweredby_mediawiki.svg" alt="Powered by MediaWiki" width="88" height="31" loading="lazy"></a></li>
</ul>

</footer>

<script>(RLQ=window.RLQ||[]).push(function(){mw.log.warn("This page is using the deprecated ResourceLoader module \"codex-search-styles\".\n[1.43] Use a CodexModule with codexComponents to set your specific components used: https://www.mediawiki.org/wiki/Codex#Using_a_limited_subset_of_components");});</script>
<script src="https://www.googletagmanager.com/gtag/js?id=G-TVBPRD78K4" async=""></script><script>
window.dataLayer = window.dataLayer || [];

function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-TVBPRD78K4', {});
</script>

<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":330,"wgPageParseReport":{"limitreport":{"cputime":"0.105","walltime":"0.209","ppvisitednodes":{"value":1319,"limit":1000000},"postexpandincludesize":{"value":24821,"limit":2097152},"templateargumentsize":{"value":23010,"limit":2097152},"expansiondepth":{"value":8,"limit":100},"expensivefunctioncount":{"value":36,"limit":100},"unstrip-depth":{"value":3,"limit":20},"unstrip-size":{"value":90254,"limit":5000000},"timingprofile":["100.00%  130.982      1 -total"," 85.28%  111.696     13 Template:File","  1.67%    2.186     14 Template:Command2","  1.44%    1.885      6 Template:Commands","  0.39%    0.506      1 Template:Command"]},"loops":{"limitreport-count-limited":{"value":0,"limit":100}},"cachereport":{"timestamp":"20250530235337","ttl":86400,"transientcontent":false}}});});</script>
</body>
</html>